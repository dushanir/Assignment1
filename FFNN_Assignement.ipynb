{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFNN Assignement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwXAk5kCvUd3sOeyu+fEDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dushanir/Assignment1/blob/main/FFNN_Assignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZr5pbGkLMHr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# importing modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Activation\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "hehoeplHbUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tVTjtIE7PHAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv( \"./crx.csv\", names=[\"A1\",\"A2\",\"A3\",\"A4\",\"A5\",\"A6\",\"A7\",\"A8\",\"A9\",\"A10\",\"A11\",\"A12\",\"A13\",\"A14\",\"A15\",\"A16\"])"
      ],
      "metadata": {
        "id": "aDRSDQeLOWKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lDndrYSWPPvo",
        "outputId": "dff6423e-9b57-40e3-8f20-0cd72bf799f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    A1     A2      A3 A4 A5  A6  A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
              "0    b  30.83   0.000  u  g   w   v  1.25  t   t    1   f   g  00202    0   +\n",
              "1    a  58.67   4.460  u  g   q   h  3.04  t   t    6   f   g  00043  560   +\n",
              "2    a  24.50   0.500  u  g   q   h  1.50  t   f    0   f   g  00280  824   +\n",
              "3    b  27.83   1.540  u  g   w   v  3.75  t   t    5   t   g  00100    3   +\n",
              "4    b  20.17   5.625  u  g   w   v  1.71  t   f    0   f   s  00120    0   +\n",
              "..  ..    ...     ... .. ..  ..  ..   ... ..  ..  ...  ..  ..    ...  ...  ..\n",
              "685  b  21.08  10.085  y  p   e   h  1.25  f   f    0   f   g  00260    0   -\n",
              "686  a  22.67   0.750  u  g   c   v  2.00  f   t    2   t   g  00200  394   -\n",
              "687  a  25.25  13.500  y  p  ff  ff  2.00  f   t    1   t   g  00200    1   -\n",
              "688  b  17.92   0.205  u  g  aa   v  0.04  f   f    0   f   g  00280  750   -\n",
              "689  b  35.00   3.375  u  g   c   h  8.29  f   f    0   t   g  00000    0   -\n",
              "\n",
              "[690 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de5b0b6d-9c23-428e-9d16-dfab366c0924\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>b</td>\n",
              "      <td>21.08</td>\n",
              "      <td>10.085</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>1.25</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00260</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>a</td>\n",
              "      <td>22.67</td>\n",
              "      <td>0.750</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>2.00</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>2</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>394</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>a</td>\n",
              "      <td>25.25</td>\n",
              "      <td>13.500</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>2.00</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00200</td>\n",
              "      <td>1</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>b</td>\n",
              "      <td>17.92</td>\n",
              "      <td>0.205</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>0.04</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>750</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>b</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3.375</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>h</td>\n",
              "      <td>8.29</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00000</td>\n",
              "      <td>0</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>690 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5b0b6d-9c23-428e-9d16-dfab366c0924')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de5b0b6d-9c23-428e-9d16-dfab366c0924 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de5b0b6d-9c23-428e-9d16-dfab366c0924');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUUVXQfpW7aX",
        "outputId": "a2e6115d-fac6-48c8-9475-1d5651d87a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 681 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      681 non-null    object \n",
            " 1   A2      681 non-null    object \n",
            " 2   A3      681 non-null    float64\n",
            " 3   A4      681 non-null    object \n",
            " 4   A5      681 non-null    object \n",
            " 5   A6      681 non-null    object \n",
            " 6   A7      681 non-null    object \n",
            " 7   A8      681 non-null    float64\n",
            " 8   A9      681 non-null    object \n",
            " 9   A10     681 non-null    object \n",
            " 10  A11     681 non-null    int64  \n",
            " 11  A12     681 non-null    object \n",
            " 12  A13     681 non-null    object \n",
            " 13  A14     681 non-null    object \n",
            " 14  A15     681 non-null    int64  \n",
            " 15  A16     681 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 106.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A1'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EW6U9fMXGBN",
        "outputId": "d878fed2-1f17-41c6-d822-acc90d12f216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['b', 'a', '?'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A1'] =data['A1'].apply(lambda x: np.nan if x == '?' else x) "
      ],
      "metadata": {
        "id": "AhfCylkjXOdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['A2'] =data['A2'].apply(lambda x: np.nan if x == '?' else x) "
      ],
      "metadata": {
        "id": "ayzd15f9Xcyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.astype({\"A2\": float})"
      ],
      "metadata": {
        "id": "E_TG2F-OZwik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['A14'] =data['A14'].apply(lambda x: np.nan if x == '?' else x) "
      ],
      "metadata": {
        "id": "J1VQo8SjZ9BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.astype({\"A14\": int})"
      ],
      "metadata": {
        "id": "rVVapu2-aVwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newd = data[['A2', 'A3', 'A8','A11','A14','A15']].copy()"
      ],
      "metadata": {
        "id": "T__NfPLLXD6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newc = data[['A1', 'A4', 'A5','A6','A7','A9','A10','A12','A13']].copy()"
      ],
      "metadata": {
        "id": "M38vvMQFgX5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2T11eoTPgw6s",
        "outputId": "5fc0fd2d-0a85-49bb-9cee-c488255db071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    A1 A4 A5  A6  A7 A9 A10 A12 A13\n",
              "0    b  u  g   w   v  t   t   f   g\n",
              "1    a  u  g   q   h  t   t   f   g\n",
              "2    a  u  g   q   h  t   f   f   g\n",
              "3    b  u  g   w   v  t   t   t   g\n",
              "4    b  u  g   w   v  t   f   f   s\n",
              "..  .. .. ..  ..  .. ..  ..  ..  ..\n",
              "685  b  y  p   e   h  f   f   f   g\n",
              "686  a  u  g   c   v  f   t   t   g\n",
              "687  a  y  p  ff  ff  f   t   t   g\n",
              "688  b  u  g  aa   v  f   f   f   g\n",
              "689  b  u  g   c   h  f   f   t   g\n",
              "\n",
              "[653 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdd01721-dfda-4f52-87f6-9bc7d43ade1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>685</th>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>e</td>\n",
              "      <td>h</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>686</th>\n",
              "      <td>a</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>v</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>a</td>\n",
              "      <td>y</td>\n",
              "      <td>p</td>\n",
              "      <td>ff</td>\n",
              "      <td>ff</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>688</th>\n",
              "      <td>b</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>aa</td>\n",
              "      <td>v</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>b</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>c</td>\n",
              "      <td>h</td>\n",
              "      <td>f</td>\n",
              "      <td>f</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>653 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdd01721-dfda-4f52-87f6-9bc7d43ade1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdd01721-dfda-4f52-87f6-9bc7d43ade1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdd01721-dfda-4f52-87f6-9bc7d43ade1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A4'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keiDgOg9SB1C",
        "outputId": "33738e31-c02f-4fd7-8b25-eb355249db5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['u', 'y', 'l'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A4'] =data['A4'].apply(lambda x: np.nan if x == '?' else x) "
      ],
      "metadata": {
        "id": "M6q__pheSjBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "Q0z6XWFDTcM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['A5'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRAmxJfMTUAJ",
        "outputId": "b2886874-5f8e-4cf1-9768-70d208ffaa6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['g', 'p', 'gg'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A6'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op2pEgVVTnub",
        "outputId": "569ce8ba-c6cf-4117-a7d6-ff259d6bec82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['w', 'q', 'm', 'r', 'cc', 'k', 'c', 'd', 'x', 'i', 'e', 'aa', 'ff',\n",
              "       'j'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A6'] =data['A6'].apply(lambda x: np.nan if x == '?' else x) "
      ],
      "metadata": {
        "id": "LmwUuI85TrDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['A7'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GmqYXhDT5L5",
        "outputId": "1c54d3da-6978-4446-a654-f5f5e9dd5a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['v', 'h', 'bb', 'ff', 'j', 'z', 'o', 'dd', 'n'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A9'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYpFb2QbT9DR",
        "outputId": "bf7e9576-4ea0-492d-fa02-825b78bd9b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['t', 'f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A10'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGZTMijpUCEq",
        "outputId": "4b561f5c-4893-44c8-82b2-5cedc34bad1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['t', 'f'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A12'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lj6Zk3MUDfB",
        "outputId": "0d2cd1d1-f17b-41d5-a943-9061f76796ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['f', 't'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A13'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAXO7E5uUKVS",
        "outputId": "09d95a9d-bf4a-4ce5-8413-b1c3989122e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['g', 's', 'p'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['A16'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmS6Oi-PUQ6S",
        "outputId": "bff7d7d4-8fb7-456a-90ed-61ca87dffa5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['+', '-'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of one hot encoding for a neural network\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " \n",
        "# load the dataset\n",
        "def load_dataset(data):\n",
        "\t\n",
        "\t# retrieve numpy array\n",
        "\tdataset = data.values\n",
        "\t# split into input (X) and output (y) variables\n",
        "\tX = dataset[:, :-1]\n",
        "\ty = dataset[:,-1]\n",
        "\t# format all fields as string\n",
        "\tX = X.astype(str)\n",
        "\t# reshape target to be a 2d array\n",
        "\ty = y.reshape((len(y), 1))\n",
        "\treturn X, y\n",
        " \n",
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(X_train)\n",
        "\tX_train_enc = ohe.transform(X_train)\n",
        "\tX_test_enc = ohe.transform(X_test)\n",
        "\treturn X_train_enc, X_test_enc\n",
        " \n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(y_train)\n",
        "\ty_train_enc = le.transform(y_train)\n",
        "\ty_test_enc = le.transform(y_test)\n",
        "\treturn y_train_enc, y_test_enc\n",
        " \n",
        "# load the dataset\n",
        "X, y = load_dataset(data)\n",
        "#X = prepare_inputs\n"
      ],
      "metadata": {
        "id": "GVu8GmQmd-VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "6oeS4gtQiFAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = data.values\n",
        "\t# split into input (X) and output (y) variables\n",
        "X = dataset[:, :-1]\n",
        "y = dataset[:,-1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
      ],
      "metadata": {
        "id": "_6mfJ1cmhvd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc_ItcHGErYH",
        "outputId": "6dacd044-bc34-4f60-a098-26991b457e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['+', '-', '+', '+', '-', '-', '-', '+', '+', '+', '-', '-', '+',\n",
              "       '-', '-', '+', '+', '+', '+', '+', '+', '-', '-', '+', '-', '+',\n",
              "       '-', '+', '+', '-', '-', '+', '+', '-', '-', '-', '-', '-', '-',\n",
              "       '+', '-', '+', '-', '-', '+', '-', '+', '-', '-', '-', '-', '+',\n",
              "       '+', '-', '-', '-', '-', '-', '+', '+', '+', '-', '-', '+', '-',\n",
              "       '+', '+', '-', '+', '+', '-', '-', '-', '+', '-', '+', '+', '+',\n",
              "       '+', '+', '-', '-', '-', '+', '-', '-', '+', '-', '-', '+', '+',\n",
              "       '-', '-', '-', '+', '-', '+', '-', '+', '-', '+', '+', '+', '-',\n",
              "       '-', '-', '-', '+', '+', '+', '+', '+', '+', '+', '+', '-', '-',\n",
              "       '+', '-', '-', '-', '-', '-', '-', '+', '-', '-', '+', '-', '+',\n",
              "       '-', '+', '-', '+', '-', '+', '+', '-', '+', '+', '-', '-', '-',\n",
              "       '+', '+', '-', '-', '+', '+', '-', '-', '-', '+', '+', '+', '+',\n",
              "       '+', '-', '+', '-', '+', '+', '-', '+', '-', '+', '-', '+', '-',\n",
              "       '-', '+', '+', '-', '+', '+', '+', '-', '-', '-', '-', '-', '+',\n",
              "       '-', '-', '-', '-', '+', '+', '+', '-', '+', '+', '-', '+', '+',\n",
              "       '+', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '+', '+',\n",
              "       '-', '+', '-', '-', '+', '-', '-', '+', '+', '-', '-', '+', '-',\n",
              "       '-', '-', '+', '+', '-', '-', '-', '-', '-', '-', '+', '+', '-',\n",
              "       '-', '-', '+', '-', '-', '-', '+', '-', '+', '-', '+', '+', '+',\n",
              "       '-', '-', '+', '-', '+', '-', '-', '+', '+', '-', '-', '+', '-',\n",
              "       '+', '+', '-', '+', '+', '+', '-', '-', '+', '+', '-', '-', '+',\n",
              "       '+', '+', '-', '+', '-', '+', '-', '-', '-', '-', '-', '-', '-',\n",
              "       '-', '+', '-', '-', '-', '+', '-', '-', '-', '-', '-', '+', '+',\n",
              "       '-', '+', '-', '-', '+', '-', '+', '+', '-', '-', '-', '-', '+',\n",
              "       '+', '-', '-', '+', '+', '+', '+', '-', '+', '+', '-', '-', '+',\n",
              "       '-', '+', '+', '+', '-', '+', '+', '-', '+', '+', '+', '+', '-',\n",
              "       '+', '+', '-', '+', '-', '-', '+', '-', '+', '-', '+', '-', '-',\n",
              "       '-', '-', '-', '+', '-', '-', '+', '+', '-', '-', '-', '-', '+',\n",
              "       '-', '+', '-', '+', '-', '-', '-', '-', '+', '-', '+', '-', '-',\n",
              "       '-', '+', '+', '-', '+', '-', '+', '+', '+', '+', '+', '-', '-',\n",
              "       '+', '+', '+', '-', '-', '-', '+', '-', '-', '-', '+', '-', '-',\n",
              "       '-', '+', '-', '-', '-', '+', '-', '+', '-', '+', '-', '+', '-',\n",
              "       '+', '-', '+', '-', '+', '-', '+', '-', '-', '-', '+', '-', '-',\n",
              "       '-', '-', '+', '+', '-', '-', '+', '+'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[: , [1, 2, 7,10,13,14]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JmgW4BujW4L",
        "outputId": "df91aa87-b811-47da-b563-66b26e43c10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44.17, 6.665, 7.375, 3, 0, 0],\n",
              "       [39.58, 5.0, 0.0, 2, 17, 1],\n",
              "       [20.17, 5.625, 1.71, 0, 120, 0],\n",
              "       ...,\n",
              "       [44.25, 0.5, 10.75, 0, 400, 0],\n",
              "       [28.33, 5.0, 11.0, 0, 70, 0],\n",
              "       [23.0, 11.75, 0.5, 2, 300, 551]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newTestc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yqGhRyQmWMH",
        "outputId": "4f453682-2973-42a6-ab19-5bd0dd3334b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['b', 'y', 'p', 'c', 'h', 't', 'f', 'f', 'g'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "\tohe = OneHotEncoder(handle_unknown='ignore')\n",
        "\tohe.fit(X_train)\n",
        "\tX_train_enc = ohe.transform(X_train)\n",
        "\tX_test_enc = ohe.transform(X_test)\n",
        "\treturn X_train_enc, X_test_enc\n",
        "\n",
        "newTraind = X_train[: , [1, 2, 7,10,13,14]].copy()\n",
        "newTrainc = X_train[:, [0, 3, 4,5,6,8,9,11,12]].copy()\n",
        "newTestd = X_test[: , [1, 2, 7,10,13,14]].copy()\n",
        "newTestc = X_test[:, [0, 3, 4,5,6,8,9,11,12]].copy()\n",
        "\n",
        "X_train_enc, X_test_enc = prepare_inputs(newTrainc, newTestc)"
      ],
      "metadata": {
        "id": "-TS-zzxXiJEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_enc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3XKzkuFFA2C",
        "outputId": "1f1efcf0-a9ac-457f-d23d-dce9a3279816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<437x39 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3933 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tle = LabelEncoder()\n",
        "\tle.fit(y_train)\n",
        "\ty_train_enc = le.transform(y_train)\n",
        "\ty_test_enc = le.transform(y_test)\n",
        "\treturn y_train_enc, y_test_enc\n",
        "\n",
        "# prepare output data\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
      ],
      "metadata": {
        "id": "yzEPJ3b-nCr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all = np.concatenate( [ newTraind, X_train_enc.toarray() ], axis = 1)"
      ],
      "metadata": {
        "id": "4RmlGw9WoleV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_all = np.concatenate( [ newTestd, X_test_enc.toarray() ], axis = 1)"
      ],
      "metadata": {
        "id": "VTvOiaJFphyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all = np.asarray(X_train_all).astype(np.float32)\n",
        "X_test_all = np.asarray(X_test_all).astype(np.float32)"
      ],
      "metadata": {
        "id": "oBDcHK3Yp9bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "X = pd.DataFrame(X_train_all)\n",
        "\n",
        "cols = X.columns\n",
        "\n",
        "ms = MinMaxScaler()\n",
        "X_train_all = ms.fit_transform(X)\n",
        "X_test_all = ms.fit_transform(pd.DataFrame(X_test_all))\n",
        " "
      ],
      "metadata": {
        "id": "GK2O11NcFWhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "477pCUKGJhgC",
        "outputId": "909bd478-0896-4945-84b6-f9ff9e4d85a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48608774, 0.23803572, 0.25877193, ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.13258463, 0.        , 0.03508772, ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.08380824, 0.20089287, 0.06      , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.48742872, 0.01785714, 0.37719297, ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.22058329, 0.17857143, 0.38596493, ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.1312437 , 0.41964287, 0.01754386, ..., 1.        , 0.        ,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "uNN2zeyhFwP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the  model\n",
        "model = Sequential()\n",
        "nodes_1 = round((X_train_all.shape[1] + 1)/2,0)\n",
        "model.add(Dense(nodes_1, input_dim=X_train_all.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train_all, y_train_enc, epochs=100, batch_size=16, verbose=2)\n",
        "# evaluate the keras model\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_all, y_test_enc, verbose=0)\n",
        "print('Accuracy: %.2f' % (accuracy*100))\n",
        "print('f1_score')\n",
        "print(f1_score)\n",
        "print('precision')\n",
        "print(precision)\n",
        "print('recall')\n",
        "print(recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usS4UzpnpydN",
        "outputId": "ab042010-a779-470f-8f1c-cf7f8488a4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "28/28 - 1s - loss: 0.6291 - accuracy: 0.7117 - f1_m: 0.7164 - precision_m: 0.7450 - recall_m: 0.7186 - 1s/epoch - 41ms/step\n",
            "Epoch 2/100\n",
            "28/28 - 0s - loss: 0.5693 - accuracy: 0.8146 - f1_m: 0.8293 - precision_m: 0.8056 - recall_m: 0.8642 - 50ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "28/28 - 0s - loss: 0.5176 - accuracy: 0.8490 - f1_m: 0.8539 - precision_m: 0.8540 - recall_m: 0.8677 - 43ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "28/28 - 0s - loss: 0.4731 - accuracy: 0.8513 - f1_m: 0.8467 - precision_m: 0.8664 - recall_m: 0.8493 - 45ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "28/28 - 0s - loss: 0.4323 - accuracy: 0.8673 - f1_m: 0.8729 - precision_m: 0.8972 - recall_m: 0.8660 - 45ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "28/28 - 0s - loss: 0.3999 - accuracy: 0.8673 - f1_m: 0.8511 - precision_m: 0.8722 - recall_m: 0.8390 - 45ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "28/28 - 0s - loss: 0.3722 - accuracy: 0.8810 - f1_m: 0.8791 - precision_m: 0.9160 - recall_m: 0.8551 - 49ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "28/28 - 0s - loss: 0.3537 - accuracy: 0.8833 - f1_m: 0.8778 - precision_m: 0.9216 - recall_m: 0.8492 - 49ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "28/28 - 0s - loss: 0.3383 - accuracy: 0.8856 - f1_m: 0.8823 - precision_m: 0.9220 - recall_m: 0.8597 - 43ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "28/28 - 0s - loss: 0.3276 - accuracy: 0.8856 - f1_m: 0.8771 - precision_m: 0.9340 - recall_m: 0.8439 - 48ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "28/28 - 0s - loss: 0.3199 - accuracy: 0.8787 - f1_m: 0.8883 - precision_m: 0.9210 - recall_m: 0.8689 - 45ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "28/28 - 0s - loss: 0.3142 - accuracy: 0.8810 - f1_m: 0.8834 - precision_m: 0.9424 - recall_m: 0.8421 - 45ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "28/28 - 0s - loss: 0.3084 - accuracy: 0.8787 - f1_m: 0.8744 - precision_m: 0.9441 - recall_m: 0.8230 - 45ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "28/28 - 0s - loss: 0.3053 - accuracy: 0.8741 - f1_m: 0.8405 - precision_m: 0.8946 - recall_m: 0.8029 - 41ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "28/28 - 0s - loss: 0.3025 - accuracy: 0.8810 - f1_m: 0.8828 - precision_m: 0.9461 - recall_m: 0.8372 - 43ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "28/28 - 0s - loss: 0.2992 - accuracy: 0.8810 - f1_m: 0.8648 - precision_m: 0.9271 - recall_m: 0.8185 - 43ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "28/28 - 0s - loss: 0.2986 - accuracy: 0.8764 - f1_m: 0.8761 - precision_m: 0.9307 - recall_m: 0.8473 - 51ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "28/28 - 0s - loss: 0.2956 - accuracy: 0.8787 - f1_m: 0.8793 - precision_m: 0.9382 - recall_m: 0.8412 - 48ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "28/28 - 0s - loss: 0.2935 - accuracy: 0.8741 - f1_m: 0.8714 - precision_m: 0.9303 - recall_m: 0.8336 - 47ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "28/28 - 0s - loss: 0.2914 - accuracy: 0.8764 - f1_m: 0.8675 - precision_m: 0.9228 - recall_m: 0.8345 - 55ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "28/28 - 0s - loss: 0.2900 - accuracy: 0.8810 - f1_m: 0.8630 - precision_m: 0.9261 - recall_m: 0.8211 - 51ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "28/28 - 0s - loss: 0.2894 - accuracy: 0.8787 - f1_m: 0.8758 - precision_m: 0.9432 - recall_m: 0.8384 - 46ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "28/28 - 0s - loss: 0.2874 - accuracy: 0.8810 - f1_m: 0.8808 - precision_m: 0.9361 - recall_m: 0.8465 - 67ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "28/28 - 0s - loss: 0.2853 - accuracy: 0.8810 - f1_m: 0.8785 - precision_m: 0.9294 - recall_m: 0.8419 - 50ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "28/28 - 0s - loss: 0.2834 - accuracy: 0.8833 - f1_m: 0.8836 - precision_m: 0.9362 - recall_m: 0.8442 - 47ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "28/28 - 0s - loss: 0.2822 - accuracy: 0.8856 - f1_m: 0.8761 - precision_m: 0.9256 - recall_m: 0.8444 - 46ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "28/28 - 0s - loss: 0.2812 - accuracy: 0.8856 - f1_m: 0.8765 - precision_m: 0.9404 - recall_m: 0.8345 - 44ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "28/28 - 0s - loss: 0.2799 - accuracy: 0.8833 - f1_m: 0.8812 - precision_m: 0.9363 - recall_m: 0.8468 - 47ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "28/28 - 0s - loss: 0.2786 - accuracy: 0.8810 - f1_m: 0.8650 - precision_m: 0.9296 - recall_m: 0.8304 - 45ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "28/28 - 0s - loss: 0.2780 - accuracy: 0.8856 - f1_m: 0.8764 - precision_m: 0.9274 - recall_m: 0.8498 - 46ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "28/28 - 0s - loss: 0.2754 - accuracy: 0.8856 - f1_m: 0.8829 - precision_m: 0.9324 - recall_m: 0.8497 - 46ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "28/28 - 0s - loss: 0.2754 - accuracy: 0.8833 - f1_m: 0.8836 - precision_m: 0.9399 - recall_m: 0.8449 - 44ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "28/28 - 0s - loss: 0.2736 - accuracy: 0.8833 - f1_m: 0.8813 - precision_m: 0.9339 - recall_m: 0.8424 - 44ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "28/28 - 0s - loss: 0.2744 - accuracy: 0.8879 - f1_m: 0.8866 - precision_m: 0.9472 - recall_m: 0.8441 - 44ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "28/28 - 0s - loss: 0.2732 - accuracy: 0.8856 - f1_m: 0.8870 - precision_m: 0.9235 - recall_m: 0.8636 - 44ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "28/28 - 0s - loss: 0.2699 - accuracy: 0.8833 - f1_m: 0.8876 - precision_m: 0.9365 - recall_m: 0.8531 - 45ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "28/28 - 0s - loss: 0.2706 - accuracy: 0.8833 - f1_m: 0.8716 - precision_m: 0.9162 - recall_m: 0.8422 - 47ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "28/28 - 0s - loss: 0.2685 - accuracy: 0.8856 - f1_m: 0.8802 - precision_m: 0.9262 - recall_m: 0.8470 - 44ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "28/28 - 0s - loss: 0.2685 - accuracy: 0.8879 - f1_m: 0.8786 - precision_m: 0.9392 - recall_m: 0.8394 - 52ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "28/28 - 0s - loss: 0.2653 - accuracy: 0.8879 - f1_m: 0.8872 - precision_m: 0.9446 - recall_m: 0.8509 - 53ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "28/28 - 0s - loss: 0.2656 - accuracy: 0.8833 - f1_m: 0.8772 - precision_m: 0.9177 - recall_m: 0.8479 - 52ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "28/28 - 0s - loss: 0.2640 - accuracy: 0.8924 - f1_m: 0.8841 - precision_m: 0.9404 - recall_m: 0.8470 - 56ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "28/28 - 0s - loss: 0.2635 - accuracy: 0.8947 - f1_m: 0.8936 - precision_m: 0.9266 - recall_m: 0.8763 - 52ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "28/28 - 0s - loss: 0.2622 - accuracy: 0.8856 - f1_m: 0.8721 - precision_m: 0.9179 - recall_m: 0.8388 - 54ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "28/28 - 0s - loss: 0.2604 - accuracy: 0.8856 - f1_m: 0.8910 - precision_m: 0.9337 - recall_m: 0.8587 - 44ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "28/28 - 0s - loss: 0.2594 - accuracy: 0.8902 - f1_m: 0.8807 - precision_m: 0.9338 - recall_m: 0.8444 - 44ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "28/28 - 0s - loss: 0.2574 - accuracy: 0.8924 - f1_m: 0.8774 - precision_m: 0.9051 - recall_m: 0.8646 - 45ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "28/28 - 0s - loss: 0.2555 - accuracy: 0.8924 - f1_m: 0.8898 - precision_m: 0.9291 - recall_m: 0.8633 - 44ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "28/28 - 0s - loss: 0.2550 - accuracy: 0.8924 - f1_m: 0.8843 - precision_m: 0.9273 - recall_m: 0.8578 - 45ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "28/28 - 0s - loss: 0.2536 - accuracy: 0.8970 - f1_m: 0.8975 - precision_m: 0.9367 - recall_m: 0.8748 - 48ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "28/28 - 0s - loss: 0.2535 - accuracy: 0.8947 - f1_m: 0.8978 - precision_m: 0.9405 - recall_m: 0.8708 - 53ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "28/28 - 0s - loss: 0.2518 - accuracy: 0.8924 - f1_m: 0.8635 - precision_m: 0.9149 - recall_m: 0.8292 - 48ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "28/28 - 0s - loss: 0.2504 - accuracy: 0.8947 - f1_m: 0.8985 - precision_m: 0.9408 - recall_m: 0.8654 - 51ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "28/28 - 0s - loss: 0.2494 - accuracy: 0.8947 - f1_m: 0.8946 - precision_m: 0.9342 - recall_m: 0.8689 - 47ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "28/28 - 0s - loss: 0.2490 - accuracy: 0.8970 - f1_m: 0.8958 - precision_m: 0.9501 - recall_m: 0.8615 - 48ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "28/28 - 0s - loss: 0.2471 - accuracy: 0.8993 - f1_m: 0.8824 - precision_m: 0.9217 - recall_m: 0.8579 - 44ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "28/28 - 0s - loss: 0.2469 - accuracy: 0.8924 - f1_m: 0.8487 - precision_m: 0.8940 - recall_m: 0.8220 - 53ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "28/28 - 0s - loss: 0.2470 - accuracy: 0.8993 - f1_m: 0.8839 - precision_m: 0.9501 - recall_m: 0.8454 - 49ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "28/28 - 0s - loss: 0.2464 - accuracy: 0.8947 - f1_m: 0.8893 - precision_m: 0.9212 - recall_m: 0.8694 - 55ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "28/28 - 0s - loss: 0.2462 - accuracy: 0.8947 - f1_m: 0.8945 - precision_m: 0.9474 - recall_m: 0.8607 - 47ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "28/28 - 0s - loss: 0.2427 - accuracy: 0.9039 - f1_m: 0.9021 - precision_m: 0.9317 - recall_m: 0.8824 - 57ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "28/28 - 0s - loss: 0.2425 - accuracy: 0.9016 - f1_m: 0.8661 - precision_m: 0.9081 - recall_m: 0.8398 - 47ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "28/28 - 0s - loss: 0.2405 - accuracy: 0.9016 - f1_m: 0.8951 - precision_m: 0.9414 - recall_m: 0.8601 - 58ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "28/28 - 0s - loss: 0.2398 - accuracy: 0.9039 - f1_m: 0.9064 - precision_m: 0.9454 - recall_m: 0.8833 - 55ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "28/28 - 0s - loss: 0.2373 - accuracy: 0.9062 - f1_m: 0.9031 - precision_m: 0.9309 - recall_m: 0.8882 - 54ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "28/28 - 0s - loss: 0.2370 - accuracy: 0.9062 - f1_m: 0.9068 - precision_m: 0.9348 - recall_m: 0.8884 - 57ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "28/28 - 0s - loss: 0.2354 - accuracy: 0.9039 - f1_m: 0.9020 - precision_m: 0.9353 - recall_m: 0.8785 - 49ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "28/28 - 0s - loss: 0.2342 - accuracy: 0.9039 - f1_m: 0.9034 - precision_m: 0.9355 - recall_m: 0.8818 - 52ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "28/28 - 0s - loss: 0.2337 - accuracy: 0.9039 - f1_m: 0.8961 - precision_m: 0.9386 - recall_m: 0.8682 - 48ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "28/28 - 0s - loss: 0.2326 - accuracy: 0.9039 - f1_m: 0.9009 - precision_m: 0.9285 - recall_m: 0.8904 - 48ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "28/28 - 0s - loss: 0.2313 - accuracy: 0.9016 - f1_m: 0.8995 - precision_m: 0.9445 - recall_m: 0.8660 - 55ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "28/28 - 0s - loss: 0.2316 - accuracy: 0.9016 - f1_m: 0.8920 - precision_m: 0.9432 - recall_m: 0.8556 - 57ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "28/28 - 0s - loss: 0.2298 - accuracy: 0.9062 - f1_m: 0.8996 - precision_m: 0.9282 - recall_m: 0.8837 - 64ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "28/28 - 0s - loss: 0.2289 - accuracy: 0.9085 - f1_m: 0.9108 - precision_m: 0.9313 - recall_m: 0.8979 - 64ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "28/28 - 0s - loss: 0.2278 - accuracy: 0.9062 - f1_m: 0.9073 - precision_m: 0.9450 - recall_m: 0.8826 - 57ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "28/28 - 0s - loss: 0.2274 - accuracy: 0.9085 - f1_m: 0.9116 - precision_m: 0.9354 - recall_m: 0.8974 - 58ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "28/28 - 0s - loss: 0.2253 - accuracy: 0.9108 - f1_m: 0.9003 - precision_m: 0.9383 - recall_m: 0.8782 - 56ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "28/28 - 0s - loss: 0.2245 - accuracy: 0.9108 - f1_m: 0.9199 - precision_m: 0.9364 - recall_m: 0.9088 - 53ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "28/28 - 0s - loss: 0.2232 - accuracy: 0.9108 - f1_m: 0.9051 - precision_m: 0.9395 - recall_m: 0.8854 - 55ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "28/28 - 0s - loss: 0.2225 - accuracy: 0.9176 - f1_m: 0.9213 - precision_m: 0.9476 - recall_m: 0.9031 - 55ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "28/28 - 0s - loss: 0.2212 - accuracy: 0.9108 - f1_m: 0.9097 - precision_m: 0.9350 - recall_m: 0.8932 - 56ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "28/28 - 0s - loss: 0.2216 - accuracy: 0.9085 - f1_m: 0.9059 - precision_m: 0.9273 - recall_m: 0.8996 - 51ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "28/28 - 0s - loss: 0.2196 - accuracy: 0.9130 - f1_m: 0.9207 - precision_m: 0.9542 - recall_m: 0.8960 - 48ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "28/28 - 0s - loss: 0.2186 - accuracy: 0.9130 - f1_m: 0.9082 - precision_m: 0.9302 - recall_m: 0.9021 - 50ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "28/28 - 0s - loss: 0.2178 - accuracy: 0.9085 - f1_m: 0.9141 - precision_m: 0.9366 - recall_m: 0.8989 - 51ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "28/28 - 0s - loss: 0.2185 - accuracy: 0.9085 - f1_m: 0.9139 - precision_m: 0.9419 - recall_m: 0.8974 - 51ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "28/28 - 0s - loss: 0.2155 - accuracy: 0.9108 - f1_m: 0.9075 - precision_m: 0.9343 - recall_m: 0.8962 - 49ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "28/28 - 0s - loss: 0.2149 - accuracy: 0.9085 - f1_m: 0.8976 - precision_m: 0.9254 - recall_m: 0.8845 - 54ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "28/28 - 0s - loss: 0.2163 - accuracy: 0.9108 - f1_m: 0.9039 - precision_m: 0.9201 - recall_m: 0.8996 - 47ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "28/28 - 0s - loss: 0.2136 - accuracy: 0.9153 - f1_m: 0.9179 - precision_m: 0.9440 - recall_m: 0.9019 - 58ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "28/28 - 0s - loss: 0.2124 - accuracy: 0.9085 - f1_m: 0.8946 - precision_m: 0.9184 - recall_m: 0.8853 - 59ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "28/28 - 0s - loss: 0.2119 - accuracy: 0.9153 - f1_m: 0.9168 - precision_m: 0.9341 - recall_m: 0.9061 - 54ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "28/28 - 0s - loss: 0.2107 - accuracy: 0.9176 - f1_m: 0.9214 - precision_m: 0.9484 - recall_m: 0.9060 - 63ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "28/28 - 0s - loss: 0.2099 - accuracy: 0.9176 - f1_m: 0.9089 - precision_m: 0.9419 - recall_m: 0.8919 - 50ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "28/28 - 0s - loss: 0.2080 - accuracy: 0.9199 - f1_m: 0.9220 - precision_m: 0.9409 - recall_m: 0.9110 - 51ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "28/28 - 0s - loss: 0.2118 - accuracy: 0.9199 - f1_m: 0.9222 - precision_m: 0.9594 - recall_m: 0.8994 - 56ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "28/28 - 0s - loss: 0.2074 - accuracy: 0.9199 - f1_m: 0.9279 - precision_m: 0.9474 - recall_m: 0.9159 - 54ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "28/28 - 0s - loss: 0.2065 - accuracy: 0.9222 - f1_m: 0.9265 - precision_m: 0.9447 - recall_m: 0.9177 - 52ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "28/28 - 0s - loss: 0.2062 - accuracy: 0.9176 - f1_m: 0.8857 - precision_m: 0.9137 - recall_m: 0.8654 - 52ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "28/28 - 0s - loss: 0.2043 - accuracy: 0.9222 - f1_m: 0.9222 - precision_m: 0.9497 - recall_m: 0.9062 - 50ms/epoch - 2ms/step\n",
            "Accuracy: 85.65\n",
            "f1_score\n",
            "0.8656677007675171\n",
            "precision\n",
            "0.9108485579490662\n",
            "recall\n",
            "0.8310338258743286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_model():\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.Input( shape =(None, 100, 47)),\n",
        "            tf.keras.layers.Dense((X_train_all.shape[1] + 2)/2, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        \n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "SsjOIfnIcj47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.regularizers import l2\n",
        "f1_score_total = 0;\n",
        "count = 0\n",
        "acc_total = 0;\n",
        "for kfold, (train, test) in enumerate(KFold(n_splits=5, \n",
        "                                shuffle=True).split(X_train_all, y_train_enc)):\n",
        "    # clear the session \n",
        "    tf.keras.backend.clear_session()\n",
        "    print(X_train_all[train].shape[1])\n",
        "    # calling the model and compile it \n",
        "    #seq_model = my_model()\n",
        "    seq_model = Sequential()\n",
        "    nodes_1 = round((X_train_all.shape[1] + 1)/2,0)\n",
        "    seq_model.add(Dense(nodes_1, input_dim=X_train_all.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(0.001)))\n",
        "    seq_model.add(Dense(4, activation='relu'))\n",
        "    seq_model.add(Dense(1, activation='sigmoid'))\n",
        "    seq_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1_m,precision_m, recall_m])\n",
        "\n",
        "    # run the model \n",
        "    seq_model.fit(X_train_all[train], y_train_enc[train], epochs=100, batch_size=100, verbose=2, validation_data=(X_train_all[test], y_train_enc[test]))\n",
        "    loss, accuracy, f1_score, precision, recall = seq_model.evaluate(X_train_all[test], y_train_enc[test], verbose=0)\n",
        "    print('Accuracy: %.2f' % (accuracy*100))\n",
        "    print('f1_score')\n",
        "    print(f1_score)\n",
        "    f1_score_total += f1_score\n",
        "    acc_total += (accuracy*100)\n",
        "    count +=1\n",
        "print('Accuracy: %.2f' % (acc_total/count))\n",
        "print('f1_score: %.4f' % (f1_score_total/count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCI_35vdau4k",
        "outputId": "e407a282-f813-4dd1-a922-c7c2371c2699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.7349 - accuracy: 0.5387 - f1_m: 0.5749 - precision_m: 0.5882 - recall_m: 0.5625 - val_loss: 0.7249 - val_accuracy: 0.5682 - val_f1_m: 0.5957 - val_precision_m: 0.5600 - val_recall_m: 0.6364 - 1s/epoch - 309ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7210 - accuracy: 0.6074 - f1_m: 0.6774 - precision_m: 0.6107 - recall_m: 0.7724 - val_loss: 0.7180 - val_accuracy: 0.6136 - val_f1_m: 0.6852 - val_precision_m: 0.5781 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7090 - accuracy: 0.6590 - f1_m: 0.7448 - precision_m: 0.6273 - recall_m: 0.9180 - val_loss: 0.7105 - val_accuracy: 0.5682 - val_f1_m: 0.6833 - val_precision_m: 0.5395 - val_recall_m: 0.9318 - 31ms/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.6967 - accuracy: 0.6705 - f1_m: 0.7502 - precision_m: 0.6170 - recall_m: 0.9612 - val_loss: 0.7021 - val_accuracy: 0.5568 - val_f1_m: 0.6777 - val_precision_m: 0.5325 - val_recall_m: 0.9318 - 33ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.6837 - accuracy: 0.6991 - f1_m: 0.7682 - precision_m: 0.6428 - recall_m: 0.9581 - val_loss: 0.6918 - val_accuracy: 0.6023 - val_f1_m: 0.7009 - val_precision_m: 0.5616 - val_recall_m: 0.9318 - 40ms/epoch - 10ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.6689 - accuracy: 0.7335 - f1_m: 0.7921 - precision_m: 0.6809 - recall_m: 0.9491 - val_loss: 0.6800 - val_accuracy: 0.6591 - val_f1_m: 0.7321 - val_precision_m: 0.6029 - val_recall_m: 0.9318 - 35ms/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.6529 - accuracy: 0.7736 - f1_m: 0.8238 - precision_m: 0.7363 - recall_m: 0.9353 - val_loss: 0.6679 - val_accuracy: 0.6705 - val_f1_m: 0.7339 - val_precision_m: 0.6154 - val_recall_m: 0.9091 - 46ms/epoch - 11ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.6366 - accuracy: 0.8052 - f1_m: 0.8324 - precision_m: 0.7713 - recall_m: 0.9068 - val_loss: 0.6550 - val_accuracy: 0.6818 - val_f1_m: 0.7358 - val_precision_m: 0.6290 - val_recall_m: 0.8864 - 37ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.6187 - accuracy: 0.8281 - f1_m: 0.8477 - precision_m: 0.8107 - recall_m: 0.8908 - val_loss: 0.6415 - val_accuracy: 0.7273 - val_f1_m: 0.7647 - val_precision_m: 0.6724 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.6001 - accuracy: 0.8367 - f1_m: 0.8513 - precision_m: 0.8275 - recall_m: 0.8831 - val_loss: 0.6270 - val_accuracy: 0.7386 - val_f1_m: 0.7723 - val_precision_m: 0.6842 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.5802 - accuracy: 0.8338 - f1_m: 0.8511 - precision_m: 0.8465 - recall_m: 0.8653 - val_loss: 0.6129 - val_accuracy: 0.7386 - val_f1_m: 0.7723 - val_precision_m: 0.6842 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.5587 - accuracy: 0.8395 - f1_m: 0.8682 - precision_m: 0.8501 - recall_m: 0.8895 - val_loss: 0.5974 - val_accuracy: 0.7386 - val_f1_m: 0.7723 - val_precision_m: 0.6842 - val_recall_m: 0.8864 - 37ms/epoch - 9ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.5377 - accuracy: 0.8510 - f1_m: 0.8668 - precision_m: 0.8612 - recall_m: 0.8740 - val_loss: 0.5809 - val_accuracy: 0.7727 - val_f1_m: 0.7959 - val_precision_m: 0.7222 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.5158 - accuracy: 0.8567 - f1_m: 0.8572 - precision_m: 0.8503 - recall_m: 0.8649 - val_loss: 0.5664 - val_accuracy: 0.7955 - val_f1_m: 0.8125 - val_precision_m: 0.7500 - val_recall_m: 0.8864 - 51ms/epoch - 13ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.4940 - accuracy: 0.8539 - f1_m: 0.8655 - precision_m: 0.8710 - recall_m: 0.8619 - val_loss: 0.5483 - val_accuracy: 0.7955 - val_f1_m: 0.8043 - val_precision_m: 0.7708 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.4717 - accuracy: 0.8682 - f1_m: 0.8781 - precision_m: 0.8912 - recall_m: 0.8663 - val_loss: 0.5335 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.4511 - accuracy: 0.8682 - f1_m: 0.8830 - precision_m: 0.9048 - recall_m: 0.8624 - val_loss: 0.5202 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 31ms/epoch - 8ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.4315 - accuracy: 0.8711 - f1_m: 0.8722 - precision_m: 0.8944 - recall_m: 0.8518 - val_loss: 0.5096 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.4132 - accuracy: 0.8768 - f1_m: 0.8849 - precision_m: 0.9162 - recall_m: 0.8567 - val_loss: 0.4966 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.3964 - accuracy: 0.8768 - f1_m: 0.8886 - precision_m: 0.9216 - recall_m: 0.8583 - val_loss: 0.4874 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 39ms/epoch - 10ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.3819 - accuracy: 0.8768 - f1_m: 0.8825 - precision_m: 0.9175 - recall_m: 0.8509 - val_loss: 0.4818 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 34ms/epoch - 9ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.3702 - accuracy: 0.8768 - f1_m: 0.8856 - precision_m: 0.9122 - recall_m: 0.8614 - val_loss: 0.4790 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 34ms/epoch - 8ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.3601 - accuracy: 0.8797 - f1_m: 0.8854 - precision_m: 0.9255 - recall_m: 0.8529 - val_loss: 0.4721 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.3501 - accuracy: 0.8825 - f1_m: 0.8821 - precision_m: 0.9179 - recall_m: 0.8504 - val_loss: 0.4734 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.3432 - accuracy: 0.8768 - f1_m: 0.8848 - precision_m: 0.9169 - recall_m: 0.8554 - val_loss: 0.4767 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 41ms/epoch - 10ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.3374 - accuracy: 0.8797 - f1_m: 0.8905 - precision_m: 0.9123 - recall_m: 0.8702 - val_loss: 0.4755 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.3314 - accuracy: 0.8797 - f1_m: 0.8797 - precision_m: 0.9219 - recall_m: 0.8448 - val_loss: 0.4685 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 32ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.3264 - accuracy: 0.8797 - f1_m: 0.8899 - precision_m: 0.9251 - recall_m: 0.8575 - val_loss: 0.4673 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 32ms/epoch - 8ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.3228 - accuracy: 0.8797 - f1_m: 0.8776 - precision_m: 0.9177 - recall_m: 0.8423 - val_loss: 0.4692 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 53ms/epoch - 13ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.3188 - accuracy: 0.8797 - f1_m: 0.8714 - precision_m: 0.9028 - recall_m: 0.8437 - val_loss: 0.4753 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 46ms/epoch - 11ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.3162 - accuracy: 0.8854 - f1_m: 0.8993 - precision_m: 0.9149 - recall_m: 0.8847 - val_loss: 0.4800 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.3132 - accuracy: 0.8854 - f1_m: 0.9003 - precision_m: 0.9141 - recall_m: 0.8880 - val_loss: 0.4777 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.3104 - accuracy: 0.8797 - f1_m: 0.8831 - precision_m: 0.9077 - recall_m: 0.8613 - val_loss: 0.4694 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.3087 - accuracy: 0.8825 - f1_m: 0.8937 - precision_m: 0.9195 - recall_m: 0.8715 - val_loss: 0.4690 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 34ms/epoch - 8ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.3056 - accuracy: 0.8854 - f1_m: 0.8941 - precision_m: 0.9188 - recall_m: 0.8723 - val_loss: 0.4751 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.3036 - accuracy: 0.8883 - f1_m: 0.8941 - precision_m: 0.9040 - recall_m: 0.8893 - val_loss: 0.4803 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 43ms/epoch - 11ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.3012 - accuracy: 0.8854 - f1_m: 0.8858 - precision_m: 0.9063 - recall_m: 0.8681 - val_loss: 0.4766 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.2990 - accuracy: 0.8883 - f1_m: 0.8990 - precision_m: 0.9136 - recall_m: 0.8855 - val_loss: 0.4775 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 34ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.2977 - accuracy: 0.8911 - f1_m: 0.8954 - precision_m: 0.9263 - recall_m: 0.8689 - val_loss: 0.4742 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.8409 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.2947 - accuracy: 0.8911 - f1_m: 0.8972 - precision_m: 0.9271 - recall_m: 0.8702 - val_loss: 0.4803 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.2927 - accuracy: 0.8883 - f1_m: 0.8934 - precision_m: 0.9128 - recall_m: 0.8757 - val_loss: 0.4853 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 39ms/epoch - 10ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.2914 - accuracy: 0.8854 - f1_m: 0.8946 - precision_m: 0.9195 - recall_m: 0.8734 - val_loss: 0.4838 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 37ms/epoch - 9ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.2893 - accuracy: 0.8883 - f1_m: 0.8973 - precision_m: 0.9185 - recall_m: 0.8776 - val_loss: 0.4820 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 35ms/epoch - 9ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.2882 - accuracy: 0.8854 - f1_m: 0.8898 - precision_m: 0.9058 - recall_m: 0.8778 - val_loss: 0.4837 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.2854 - accuracy: 0.8883 - f1_m: 0.8964 - precision_m: 0.9098 - recall_m: 0.8845 - val_loss: 0.4793 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.2836 - accuracy: 0.8968 - f1_m: 0.9008 - precision_m: 0.9189 - recall_m: 0.8847 - val_loss: 0.4768 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 34ms/epoch - 8ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.2824 - accuracy: 0.8997 - f1_m: 0.9073 - precision_m: 0.9394 - recall_m: 0.8786 - val_loss: 0.4775 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 34ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.2802 - accuracy: 0.8968 - f1_m: 0.8949 - precision_m: 0.9317 - recall_m: 0.8637 - val_loss: 0.4808 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 33ms/epoch - 8ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.2795 - accuracy: 0.8883 - f1_m: 0.8964 - precision_m: 0.9135 - recall_m: 0.8802 - val_loss: 0.4876 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 31ms/epoch - 8ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.2774 - accuracy: 0.8883 - f1_m: 0.9001 - precision_m: 0.9104 - recall_m: 0.8913 - val_loss: 0.4825 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 32ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.2758 - accuracy: 0.8911 - f1_m: 0.9029 - precision_m: 0.9315 - recall_m: 0.8779 - val_loss: 0.4760 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 58ms/epoch - 15ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.2738 - accuracy: 0.9026 - f1_m: 0.9083 - precision_m: 0.9313 - recall_m: 0.8907 - val_loss: 0.4760 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 39ms/epoch - 10ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.2716 - accuracy: 0.8997 - f1_m: 0.8994 - precision_m: 0.9229 - recall_m: 0.8786 - val_loss: 0.4767 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 36ms/epoch - 9ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.2702 - accuracy: 0.8997 - f1_m: 0.8941 - precision_m: 0.9358 - recall_m: 0.8600 - val_loss: 0.4775 - val_accuracy: 0.8295 - val_f1_m: 0.8315 - val_precision_m: 0.8222 - val_recall_m: 0.8409 - 40ms/epoch - 10ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.2685 - accuracy: 0.8997 - f1_m: 0.9081 - precision_m: 0.9360 - recall_m: 0.8827 - val_loss: 0.4869 - val_accuracy: 0.8182 - val_f1_m: 0.8222 - val_precision_m: 0.8043 - val_recall_m: 0.8409 - 42ms/epoch - 10ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.2679 - accuracy: 0.8997 - f1_m: 0.8995 - precision_m: 0.9323 - recall_m: 0.8749 - val_loss: 0.4861 - val_accuracy: 0.8295 - val_f1_m: 0.8352 - val_precision_m: 0.8085 - val_recall_m: 0.8636 - 35ms/epoch - 9ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.2658 - accuracy: 0.9026 - f1_m: 0.8990 - precision_m: 0.9202 - recall_m: 0.8799 - val_loss: 0.4957 - val_accuracy: 0.7955 - val_f1_m: 0.8085 - val_precision_m: 0.7600 - val_recall_m: 0.8636 - 33ms/epoch - 8ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.2637 - accuracy: 0.9083 - f1_m: 0.9078 - precision_m: 0.9244 - recall_m: 0.8920 - val_loss: 0.4839 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 31ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.2607 - accuracy: 0.9054 - f1_m: 0.9207 - precision_m: 0.9329 - recall_m: 0.9102 - val_loss: 0.4779 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 33ms/epoch - 8ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.2583 - accuracy: 0.9083 - f1_m: 0.9136 - precision_m: 0.9310 - recall_m: 0.8995 - val_loss: 0.4742 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 37ms/epoch - 9ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.2575 - accuracy: 0.9083 - f1_m: 0.9182 - precision_m: 0.9460 - recall_m: 0.8928 - val_loss: 0.4728 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 35ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.2562 - accuracy: 0.9083 - f1_m: 0.9090 - precision_m: 0.9407 - recall_m: 0.8795 - val_loss: 0.4798 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 33ms/epoch - 8ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.2537 - accuracy: 0.9054 - f1_m: 0.9067 - precision_m: 0.9261 - recall_m: 0.8897 - val_loss: 0.4958 - val_accuracy: 0.8068 - val_f1_m: 0.8211 - val_precision_m: 0.7647 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.2527 - accuracy: 0.9112 - f1_m: 0.9064 - precision_m: 0.9200 - recall_m: 0.8933 - val_loss: 0.4935 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 34ms/epoch - 8ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.2503 - accuracy: 0.9140 - f1_m: 0.9245 - precision_m: 0.9452 - recall_m: 0.9053 - val_loss: 0.4796 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 39ms/epoch - 10ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.2485 - accuracy: 0.9140 - f1_m: 0.9185 - precision_m: 0.9456 - recall_m: 0.8933 - val_loss: 0.4830 - val_accuracy: 0.8409 - val_f1_m: 0.8444 - val_precision_m: 0.8261 - val_recall_m: 0.8636 - 38ms/epoch - 10ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.2463 - accuracy: 0.9140 - f1_m: 0.9124 - precision_m: 0.9371 - recall_m: 0.8893 - val_loss: 0.4911 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 34ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.2452 - accuracy: 0.9198 - f1_m: 0.9273 - precision_m: 0.9429 - recall_m: 0.9122 - val_loss: 0.4988 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.2438 - accuracy: 0.9198 - f1_m: 0.9269 - precision_m: 0.9453 - recall_m: 0.9120 - val_loss: 0.4949 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.2418 - accuracy: 0.9198 - f1_m: 0.9137 - precision_m: 0.9313 - recall_m: 0.8970 - val_loss: 0.4878 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 34ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.2401 - accuracy: 0.9226 - f1_m: 0.9260 - precision_m: 0.9408 - recall_m: 0.9122 - val_loss: 0.4897 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.2379 - accuracy: 0.9226 - f1_m: 0.9290 - precision_m: 0.9466 - recall_m: 0.9136 - val_loss: 0.4857 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.8298 - val_recall_m: 0.8864 - 36ms/epoch - 9ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.2362 - accuracy: 0.9226 - f1_m: 0.9292 - precision_m: 0.9476 - recall_m: 0.9122 - val_loss: 0.4871 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.2349 - accuracy: 0.9226 - f1_m: 0.9284 - precision_m: 0.9503 - recall_m: 0.9095 - val_loss: 0.4913 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 52ms/epoch - 13ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.2332 - accuracy: 0.9198 - f1_m: 0.9254 - precision_m: 0.9404 - recall_m: 0.9119 - val_loss: 0.5042 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.2309 - accuracy: 0.9226 - f1_m: 0.9182 - precision_m: 0.9291 - recall_m: 0.9078 - val_loss: 0.5028 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.2293 - accuracy: 0.9198 - f1_m: 0.9183 - precision_m: 0.9429 - recall_m: 0.8975 - val_loss: 0.4972 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 38ms/epoch - 9ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.2271 - accuracy: 0.9226 - f1_m: 0.9228 - precision_m: 0.9463 - recall_m: 0.9015 - val_loss: 0.5037 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 52ms/epoch - 13ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.2263 - accuracy: 0.9284 - f1_m: 0.9382 - precision_m: 0.9513 - recall_m: 0.9259 - val_loss: 0.5103 - val_accuracy: 0.8068 - val_f1_m: 0.8211 - val_precision_m: 0.7647 - val_recall_m: 0.8864 - 36ms/epoch - 9ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.2254 - accuracy: 0.9284 - f1_m: 0.9175 - precision_m: 0.9478 - recall_m: 0.8929 - val_loss: 0.4948 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.2220 - accuracy: 0.9312 - f1_m: 0.9316 - precision_m: 0.9445 - recall_m: 0.9192 - val_loss: 0.4980 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.2204 - accuracy: 0.9312 - f1_m: 0.9332 - precision_m: 0.9517 - recall_m: 0.9164 - val_loss: 0.4907 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 34ms/epoch - 9ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.2182 - accuracy: 0.9284 - f1_m: 0.9283 - precision_m: 0.9469 - recall_m: 0.9107 - val_loss: 0.4962 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 31ms/epoch - 8ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.2163 - accuracy: 0.9341 - f1_m: 0.9368 - precision_m: 0.9523 - recall_m: 0.9222 - val_loss: 0.5008 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 36ms/epoch - 9ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.2157 - accuracy: 0.9341 - f1_m: 0.9357 - precision_m: 0.9516 - recall_m: 0.9210 - val_loss: 0.5093 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.2130 - accuracy: 0.9341 - f1_m: 0.9355 - precision_m: 0.9567 - recall_m: 0.9159 - val_loss: 0.4991 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 32ms/epoch - 8ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.2118 - accuracy: 0.9341 - f1_m: 0.9329 - precision_m: 0.9556 - recall_m: 0.9118 - val_loss: 0.4968 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 31ms/epoch - 8ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.2101 - accuracy: 0.9398 - f1_m: 0.9450 - precision_m: 0.9585 - recall_m: 0.9349 - val_loss: 0.5053 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.2080 - accuracy: 0.9398 - f1_m: 0.9460 - precision_m: 0.9558 - recall_m: 0.9383 - val_loss: 0.5022 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.8125 - val_recall_m: 0.8864 - 34ms/epoch - 8ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.2063 - accuracy: 0.9341 - f1_m: 0.9364 - precision_m: 0.9612 - recall_m: 0.9132 - val_loss: 0.4963 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.8298 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.2051 - accuracy: 0.9370 - f1_m: 0.9417 - precision_m: 0.9669 - recall_m: 0.9190 - val_loss: 0.5083 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.2033 - accuracy: 0.9398 - f1_m: 0.9463 - precision_m: 0.9632 - recall_m: 0.9310 - val_loss: 0.5252 - val_accuracy: 0.8068 - val_f1_m: 0.8211 - val_precision_m: 0.7647 - val_recall_m: 0.8864 - 34ms/epoch - 8ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.2024 - accuracy: 0.9398 - f1_m: 0.9359 - precision_m: 0.9553 - recall_m: 0.9184 - val_loss: 0.5190 - val_accuracy: 0.8068 - val_f1_m: 0.8211 - val_precision_m: 0.7647 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.2003 - accuracy: 0.9398 - f1_m: 0.9485 - precision_m: 0.9613 - recall_m: 0.9368 - val_loss: 0.5144 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.1976 - accuracy: 0.9398 - f1_m: 0.9488 - precision_m: 0.9663 - recall_m: 0.9328 - val_loss: 0.5031 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.8298 - val_recall_m: 0.8864 - 33ms/epoch - 8ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.1986 - accuracy: 0.9427 - f1_m: 0.9466 - precision_m: 0.9696 - recall_m: 0.9249 - val_loss: 0.5053 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.8298 - val_recall_m: 0.8864 - 38ms/epoch - 9ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.1966 - accuracy: 0.9370 - f1_m: 0.9431 - precision_m: 0.9613 - recall_m: 0.9260 - val_loss: 0.5363 - val_accuracy: 0.7955 - val_f1_m: 0.8125 - val_precision_m: 0.7500 - val_recall_m: 0.8864 - 35ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.1941 - accuracy: 0.9484 - f1_m: 0.9481 - precision_m: 0.9629 - recall_m: 0.9345 - val_loss: 0.5254 - val_accuracy: 0.8182 - val_f1_m: 0.8298 - val_precision_m: 0.7800 - val_recall_m: 0.8864 - 37ms/epoch - 9ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.1925 - accuracy: 0.9427 - f1_m: 0.9461 - precision_m: 0.9621 - recall_m: 0.9310 - val_loss: 0.5115 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.8298 - val_recall_m: 0.8864 - 36ms/epoch - 9ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.1910 - accuracy: 0.9456 - f1_m: 0.9524 - precision_m: 0.9667 - recall_m: 0.9390 - val_loss: 0.5231 - val_accuracy: 0.8295 - val_f1_m: 0.8387 - val_precision_m: 0.7959 - val_recall_m: 0.8864 - 41ms/epoch - 10ms/step\n",
            "Accuracy: 82.95\n",
            "f1_score\n",
            "0.8407695293426514\n",
            "45\n",
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.8020 - accuracy: 0.4728 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7670 - val_accuracy: 0.4318 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 1s/epoch - 255ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7671 - accuracy: 0.4728 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7425 - val_accuracy: 0.4318 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 36ms/epoch - 9ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7438 - accuracy: 0.4728 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7248 - val_accuracy: 0.4318 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00 - 35ms/epoch - 9ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7287 - accuracy: 0.4670 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.7121 - val_accuracy: 0.4432 - val_f1_m: 0.0392 - val_precision_m: 1.0000 - val_recall_m: 0.0200 - 34ms/epoch - 9ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.7164 - accuracy: 0.4928 - f1_m: 0.1038 - precision_m: 0.7917 - recall_m: 0.0562 - val_loss: 0.7022 - val_accuracy: 0.4659 - val_f1_m: 0.1132 - val_precision_m: 1.0000 - val_recall_m: 0.0600 - 33ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.7078 - accuracy: 0.5387 - f1_m: 0.2515 - precision_m: 0.9036 - recall_m: 0.1483 - val_loss: 0.6938 - val_accuracy: 0.5227 - val_f1_m: 0.2759 - val_precision_m: 1.0000 - val_recall_m: 0.1600 - 34ms/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.7004 - accuracy: 0.5673 - f1_m: 0.3450 - precision_m: 0.9111 - recall_m: 0.2156 - val_loss: 0.6868 - val_accuracy: 0.5455 - val_f1_m: 0.3333 - val_precision_m: 1.0000 - val_recall_m: 0.2000 - 35ms/epoch - 9ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.6931 - accuracy: 0.5931 - f1_m: 0.4099 - precision_m: 0.9044 - recall_m: 0.2705 - val_loss: 0.6797 - val_accuracy: 0.5568 - val_f1_m: 0.3607 - val_precision_m: 1.0000 - val_recall_m: 0.2200 - 35ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.6866 - accuracy: 0.6017 - f1_m: 0.4044 - precision_m: 0.8869 - recall_m: 0.2642 - val_loss: 0.6731 - val_accuracy: 0.6136 - val_f1_m: 0.4848 - val_precision_m: 1.0000 - val_recall_m: 0.3200 - 34ms/epoch - 8ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.6793 - accuracy: 0.6218 - f1_m: 0.4556 - precision_m: 0.8939 - recall_m: 0.3068 - val_loss: 0.6666 - val_accuracy: 0.6364 - val_f1_m: 0.5294 - val_precision_m: 1.0000 - val_recall_m: 0.3600 - 32ms/epoch - 8ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.6725 - accuracy: 0.6447 - f1_m: 0.5343 - precision_m: 0.8897 - recall_m: 0.3837 - val_loss: 0.6598 - val_accuracy: 0.6818 - val_f1_m: 0.6111 - val_precision_m: 1.0000 - val_recall_m: 0.4400 - 34ms/epoch - 8ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.6650 - accuracy: 0.6619 - f1_m: 0.5647 - precision_m: 0.9041 - recall_m: 0.4128 - val_loss: 0.6527 - val_accuracy: 0.6932 - val_f1_m: 0.6301 - val_precision_m: 1.0000 - val_recall_m: 0.4600 - 40ms/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.6575 - accuracy: 0.6791 - f1_m: 0.5972 - precision_m: 0.9146 - recall_m: 0.4469 - val_loss: 0.6452 - val_accuracy: 0.7045 - val_f1_m: 0.6486 - val_precision_m: 1.0000 - val_recall_m: 0.4800 - 32ms/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.6505 - accuracy: 0.7077 - f1_m: 0.6500 - precision_m: 0.9067 - recall_m: 0.5072 - val_loss: 0.6372 - val_accuracy: 0.7273 - val_f1_m: 0.6842 - val_precision_m: 1.0000 - val_recall_m: 0.5200 - 34ms/epoch - 9ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.6430 - accuracy: 0.7163 - f1_m: 0.6531 - precision_m: 0.8890 - recall_m: 0.5179 - val_loss: 0.6301 - val_accuracy: 0.7614 - val_f1_m: 0.7342 - val_precision_m: 1.0000 - val_recall_m: 0.5800 - 40ms/epoch - 10ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.6358 - accuracy: 0.7307 - f1_m: 0.6752 - precision_m: 0.9066 - recall_m: 0.5382 - val_loss: 0.6236 - val_accuracy: 0.7841 - val_f1_m: 0.7654 - val_precision_m: 1.0000 - val_recall_m: 0.6200 - 35ms/epoch - 9ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.6290 - accuracy: 0.7393 - f1_m: 0.7031 - precision_m: 0.9162 - recall_m: 0.5722 - val_loss: 0.6170 - val_accuracy: 0.7841 - val_f1_m: 0.7654 - val_precision_m: 1.0000 - val_recall_m: 0.6200 - 33ms/epoch - 8ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.6222 - accuracy: 0.7507 - f1_m: 0.7124 - precision_m: 0.9126 - recall_m: 0.5851 - val_loss: 0.6109 - val_accuracy: 0.7955 - val_f1_m: 0.7805 - val_precision_m: 1.0000 - val_recall_m: 0.6400 - 33ms/epoch - 8ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.6150 - accuracy: 0.7593 - f1_m: 0.7182 - precision_m: 0.9005 - recall_m: 0.5979 - val_loss: 0.6051 - val_accuracy: 0.8068 - val_f1_m: 0.7952 - val_precision_m: 1.0000 - val_recall_m: 0.6600 - 34ms/epoch - 9ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.6086 - accuracy: 0.7736 - f1_m: 0.7345 - precision_m: 0.9144 - recall_m: 0.6158 - val_loss: 0.5994 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 35ms/epoch - 9ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.6016 - accuracy: 0.7851 - f1_m: 0.7611 - precision_m: 0.9261 - recall_m: 0.6463 - val_loss: 0.5945 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 33ms/epoch - 8ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.5952 - accuracy: 0.7966 - f1_m: 0.7863 - precision_m: 0.9136 - recall_m: 0.6948 - val_loss: 0.5898 - val_accuracy: 0.8068 - val_f1_m: 0.7952 - val_precision_m: 1.0000 - val_recall_m: 0.6600 - 34ms/epoch - 9ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.5895 - accuracy: 0.8109 - f1_m: 0.8007 - precision_m: 0.9130 - recall_m: 0.7172 - val_loss: 0.5850 - val_accuracy: 0.8068 - val_f1_m: 0.7952 - val_precision_m: 1.0000 - val_recall_m: 0.6600 - 33ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.5830 - accuracy: 0.8195 - f1_m: 0.8016 - precision_m: 0.9362 - recall_m: 0.7012 - val_loss: 0.5814 - val_accuracy: 0.7955 - val_f1_m: 0.7805 - val_precision_m: 1.0000 - val_recall_m: 0.6400 - 46ms/epoch - 11ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.5773 - accuracy: 0.8252 - f1_m: 0.8081 - precision_m: 0.9379 - recall_m: 0.7120 - val_loss: 0.5781 - val_accuracy: 0.7955 - val_f1_m: 0.7805 - val_precision_m: 1.0000 - val_recall_m: 0.6400 - 32ms/epoch - 8ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.5726 - accuracy: 0.8281 - f1_m: 0.8175 - precision_m: 0.9390 - recall_m: 0.7249 - val_loss: 0.5755 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 39ms/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.5669 - accuracy: 0.8309 - f1_m: 0.8068 - precision_m: 0.9468 - recall_m: 0.7092 - val_loss: 0.5732 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 33ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.5622 - accuracy: 0.8338 - f1_m: 0.8234 - precision_m: 0.9379 - recall_m: 0.7356 - val_loss: 0.5713 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 33ms/epoch - 8ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.5576 - accuracy: 0.8367 - f1_m: 0.8257 - precision_m: 0.9309 - recall_m: 0.7435 - val_loss: 0.5699 - val_accuracy: 0.8295 - val_f1_m: 0.8235 - val_precision_m: 1.0000 - val_recall_m: 0.7000 - 32ms/epoch - 8ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.5531 - accuracy: 0.8481 - f1_m: 0.8299 - precision_m: 0.9447 - recall_m: 0.7421 - val_loss: 0.5686 - val_accuracy: 0.8295 - val_f1_m: 0.8235 - val_precision_m: 1.0000 - val_recall_m: 0.7000 - 33ms/epoch - 8ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.5491 - accuracy: 0.8539 - f1_m: 0.8529 - precision_m: 0.9498 - recall_m: 0.7751 - val_loss: 0.5683 - val_accuracy: 0.8182 - val_f1_m: 0.8095 - val_precision_m: 1.0000 - val_recall_m: 0.6800 - 36ms/epoch - 9ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.5451 - accuracy: 0.8567 - f1_m: 0.8543 - precision_m: 0.9500 - recall_m: 0.7763 - val_loss: 0.5678 - val_accuracy: 0.8295 - val_f1_m: 0.8235 - val_precision_m: 1.0000 - val_recall_m: 0.7000 - 35ms/epoch - 9ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.5413 - accuracy: 0.8596 - f1_m: 0.8491 - precision_m: 0.9519 - recall_m: 0.7698 - val_loss: 0.5672 - val_accuracy: 0.8295 - val_f1_m: 0.8235 - val_precision_m: 1.0000 - val_recall_m: 0.7000 - 35ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.5378 - accuracy: 0.8653 - f1_m: 0.8710 - precision_m: 0.9402 - recall_m: 0.8170 - val_loss: 0.5661 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 35ms/epoch - 9ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.5341 - accuracy: 0.8625 - f1_m: 0.8595 - precision_m: 0.9458 - recall_m: 0.7902 - val_loss: 0.5667 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 34ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.5301 - accuracy: 0.8625 - f1_m: 0.8587 - precision_m: 0.9316 - recall_m: 0.7980 - val_loss: 0.5673 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 34ms/epoch - 8ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.5268 - accuracy: 0.8653 - f1_m: 0.8717 - precision_m: 0.9352 - recall_m: 0.8223 - val_loss: 0.5686 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 43ms/epoch - 11ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.5239 - accuracy: 0.8711 - f1_m: 0.8622 - precision_m: 0.9435 - recall_m: 0.7954 - val_loss: 0.5701 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 36ms/epoch - 9ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.5203 - accuracy: 0.8711 - f1_m: 0.8694 - precision_m: 0.9501 - recall_m: 0.8022 - val_loss: 0.5706 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 39ms/epoch - 10ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.5170 - accuracy: 0.8682 - f1_m: 0.8600 - precision_m: 0.9360 - recall_m: 0.7978 - val_loss: 0.5700 - val_accuracy: 0.8295 - val_f1_m: 0.8276 - val_precision_m: 0.9730 - val_recall_m: 0.7200 - 35ms/epoch - 9ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.5140 - accuracy: 0.8711 - f1_m: 0.8713 - precision_m: 0.9414 - recall_m: 0.8127 - val_loss: 0.5697 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.9737 - val_recall_m: 0.7400 - 34ms/epoch - 8ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.5107 - accuracy: 0.8711 - f1_m: 0.8688 - precision_m: 0.9460 - recall_m: 0.8045 - val_loss: 0.5697 - val_accuracy: 0.8409 - val_f1_m: 0.8409 - val_precision_m: 0.9737 - val_recall_m: 0.7400 - 35ms/epoch - 9ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.5078 - accuracy: 0.8711 - f1_m: 0.8756 - precision_m: 0.9386 - recall_m: 0.8229 - val_loss: 0.5700 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 34ms/epoch - 8ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.5048 - accuracy: 0.8739 - f1_m: 0.8721 - precision_m: 0.9329 - recall_m: 0.8197 - val_loss: 0.5703 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 37ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.5017 - accuracy: 0.8768 - f1_m: 0.8691 - precision_m: 0.9285 - recall_m: 0.8171 - val_loss: 0.5719 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 38ms/epoch - 10ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.4992 - accuracy: 0.8768 - f1_m: 0.8808 - precision_m: 0.9349 - recall_m: 0.8362 - val_loss: 0.5730 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 35ms/epoch - 9ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.4961 - accuracy: 0.8825 - f1_m: 0.8876 - precision_m: 0.9368 - recall_m: 0.8473 - val_loss: 0.5747 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 36ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.4937 - accuracy: 0.8883 - f1_m: 0.8851 - precision_m: 0.9398 - recall_m: 0.8367 - val_loss: 0.5765 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 42ms/epoch - 10ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.4907 - accuracy: 0.8883 - f1_m: 0.8855 - precision_m: 0.9402 - recall_m: 0.8375 - val_loss: 0.5766 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 36ms/epoch - 9ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.4878 - accuracy: 0.8911 - f1_m: 0.8899 - precision_m: 0.9316 - recall_m: 0.8531 - val_loss: 0.5745 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 31ms/epoch - 8ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.4855 - accuracy: 0.8911 - f1_m: 0.8934 - precision_m: 0.9348 - recall_m: 0.8575 - val_loss: 0.5762 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 36ms/epoch - 9ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.4821 - accuracy: 0.8997 - f1_m: 0.8957 - precision_m: 0.9455 - recall_m: 0.8519 - val_loss: 0.5810 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 34ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.4794 - accuracy: 0.8911 - f1_m: 0.8974 - precision_m: 0.9477 - recall_m: 0.8530 - val_loss: 0.5837 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 31ms/epoch - 8ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.4767 - accuracy: 0.8968 - f1_m: 0.8954 - precision_m: 0.9514 - recall_m: 0.8456 - val_loss: 0.5824 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 32ms/epoch - 8ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.4737 - accuracy: 0.8997 - f1_m: 0.8981 - precision_m: 0.9564 - recall_m: 0.8481 - val_loss: 0.5821 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 32ms/epoch - 8ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.4705 - accuracy: 0.8997 - f1_m: 0.8895 - precision_m: 0.9322 - recall_m: 0.8508 - val_loss: 0.5820 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 36ms/epoch - 9ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.4681 - accuracy: 0.9054 - f1_m: 0.9094 - precision_m: 0.9530 - recall_m: 0.8699 - val_loss: 0.5811 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 33ms/epoch - 8ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.4654 - accuracy: 0.9054 - f1_m: 0.9081 - precision_m: 0.9478 - recall_m: 0.8716 - val_loss: 0.5828 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 39ms/epoch - 10ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.4621 - accuracy: 0.9026 - f1_m: 0.9045 - precision_m: 0.9534 - recall_m: 0.8613 - val_loss: 0.5849 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 37ms/epoch - 9ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.4597 - accuracy: 0.9026 - f1_m: 0.8942 - precision_m: 0.9473 - recall_m: 0.8500 - val_loss: 0.5865 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 34ms/epoch - 8ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.4567 - accuracy: 0.9083 - f1_m: 0.9053 - precision_m: 0.9555 - recall_m: 0.8637 - val_loss: 0.5867 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 32ms/epoch - 8ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.4537 - accuracy: 0.9054 - f1_m: 0.9087 - precision_m: 0.9507 - recall_m: 0.8715 - val_loss: 0.5871 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 32ms/epoch - 8ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.4509 - accuracy: 0.9026 - f1_m: 0.8892 - precision_m: 0.9411 - recall_m: 0.8435 - val_loss: 0.5889 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 32ms/epoch - 8ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.4481 - accuracy: 0.9112 - f1_m: 0.9142 - precision_m: 0.9526 - recall_m: 0.8794 - val_loss: 0.5857 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 36ms/epoch - 9ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.4453 - accuracy: 0.9112 - f1_m: 0.9076 - precision_m: 0.9535 - recall_m: 0.8677 - val_loss: 0.5848 - val_accuracy: 0.8523 - val_f1_m: 0.8539 - val_precision_m: 0.9744 - val_recall_m: 0.7600 - 34ms/epoch - 9ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.4426 - accuracy: 0.9112 - f1_m: 0.9041 - precision_m: 0.9604 - recall_m: 0.8575 - val_loss: 0.5853 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 37ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.4396 - accuracy: 0.9140 - f1_m: 0.9129 - precision_m: 0.9586 - recall_m: 0.8724 - val_loss: 0.5894 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 33ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.4368 - accuracy: 0.9140 - f1_m: 0.9154 - precision_m: 0.9621 - recall_m: 0.8736 - val_loss: 0.5945 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 39ms/epoch - 10ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.4338 - accuracy: 0.9140 - f1_m: 0.9211 - precision_m: 0.9579 - recall_m: 0.8883 - val_loss: 0.5916 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 33ms/epoch - 8ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.4311 - accuracy: 0.9198 - f1_m: 0.9149 - precision_m: 0.9649 - recall_m: 0.8729 - val_loss: 0.5935 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 34ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.4286 - accuracy: 0.9198 - f1_m: 0.9260 - precision_m: 0.9651 - recall_m: 0.8904 - val_loss: 0.5980 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 40ms/epoch - 10ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.4259 - accuracy: 0.9255 - f1_m: 0.9284 - precision_m: 0.9647 - recall_m: 0.8959 - val_loss: 0.5965 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 47ms/epoch - 12ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.4236 - accuracy: 0.9255 - f1_m: 0.9312 - precision_m: 0.9594 - recall_m: 0.9052 - val_loss: 0.5997 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 38ms/epoch - 10ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.4205 - accuracy: 0.9255 - f1_m: 0.9275 - precision_m: 0.9570 - recall_m: 0.9005 - val_loss: 0.6030 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 37ms/epoch - 9ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.4189 - accuracy: 0.9255 - f1_m: 0.9225 - precision_m: 0.9533 - recall_m: 0.8954 - val_loss: 0.6032 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 34ms/epoch - 8ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.4165 - accuracy: 0.9284 - f1_m: 0.9327 - precision_m: 0.9589 - recall_m: 0.9083 - val_loss: 0.6007 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 32ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.4134 - accuracy: 0.9284 - f1_m: 0.9316 - precision_m: 0.9597 - recall_m: 0.9051 - val_loss: 0.6016 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 34ms/epoch - 9ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.4110 - accuracy: 0.9255 - f1_m: 0.9266 - precision_m: 0.9558 - recall_m: 0.8998 - val_loss: 0.6052 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 37ms/epoch - 9ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.4097 - accuracy: 0.9255 - f1_m: 0.9225 - precision_m: 0.9593 - recall_m: 0.8891 - val_loss: 0.6119 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.9512 - val_recall_m: 0.7800 - 45ms/epoch - 11ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.4069 - accuracy: 0.9284 - f1_m: 0.9348 - precision_m: 0.9645 - recall_m: 0.9093 - val_loss: 0.6029 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 35ms/epoch - 9ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.4052 - accuracy: 0.9341 - f1_m: 0.9372 - precision_m: 0.9613 - recall_m: 0.9157 - val_loss: 0.6049 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 34ms/epoch - 9ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.4024 - accuracy: 0.9312 - f1_m: 0.9393 - precision_m: 0.9662 - recall_m: 0.9150 - val_loss: 0.6092 - val_accuracy: 0.8523 - val_f1_m: 0.8571 - val_precision_m: 0.9512 - val_recall_m: 0.7800 - 33ms/epoch - 8ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.4004 - accuracy: 0.9255 - f1_m: 0.9283 - precision_m: 0.9574 - recall_m: 0.9037 - val_loss: 0.6162 - val_accuracy: 0.8636 - val_f1_m: 0.8667 - val_precision_m: 0.9750 - val_recall_m: 0.7800 - 33ms/epoch - 8ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.3981 - accuracy: 0.9255 - f1_m: 0.9302 - precision_m: 0.9644 - recall_m: 0.8987 - val_loss: 0.6116 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 35ms/epoch - 9ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.3957 - accuracy: 0.9284 - f1_m: 0.9377 - precision_m: 0.9655 - recall_m: 0.9116 - val_loss: 0.6079 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 35ms/epoch - 9ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.3933 - accuracy: 0.9312 - f1_m: 0.9291 - precision_m: 0.9581 - recall_m: 0.9026 - val_loss: 0.6145 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 36ms/epoch - 9ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.3910 - accuracy: 0.9312 - f1_m: 0.9213 - precision_m: 0.9559 - recall_m: 0.8903 - val_loss: 0.6194 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 38ms/epoch - 10ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.3894 - accuracy: 0.9341 - f1_m: 0.9391 - precision_m: 0.9579 - recall_m: 0.9228 - val_loss: 0.6156 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 37ms/epoch - 9ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.3871 - accuracy: 0.9370 - f1_m: 0.9426 - precision_m: 0.9621 - recall_m: 0.9262 - val_loss: 0.6158 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 41ms/epoch - 10ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.3850 - accuracy: 0.9370 - f1_m: 0.9297 - precision_m: 0.9499 - recall_m: 0.9118 - val_loss: 0.6191 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 38ms/epoch - 10ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.3827 - accuracy: 0.9427 - f1_m: 0.9441 - precision_m: 0.9599 - recall_m: 0.9295 - val_loss: 0.6206 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 38ms/epoch - 10ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.3809 - accuracy: 0.9456 - f1_m: 0.9499 - precision_m: 0.9660 - recall_m: 0.9348 - val_loss: 0.6178 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 40ms/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.3790 - accuracy: 0.9456 - f1_m: 0.9427 - precision_m: 0.9656 - recall_m: 0.9232 - val_loss: 0.6194 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 39ms/epoch - 10ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.3771 - accuracy: 0.9456 - f1_m: 0.9505 - precision_m: 0.9615 - recall_m: 0.9406 - val_loss: 0.6174 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 38ms/epoch - 9ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.3748 - accuracy: 0.9484 - f1_m: 0.9547 - precision_m: 0.9637 - recall_m: 0.9459 - val_loss: 0.6227 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 38ms/epoch - 10ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.3729 - accuracy: 0.9484 - f1_m: 0.9564 - precision_m: 0.9658 - recall_m: 0.9482 - val_loss: 0.6231 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 41ms/epoch - 10ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.3708 - accuracy: 0.9484 - f1_m: 0.9497 - precision_m: 0.9617 - recall_m: 0.9384 - val_loss: 0.6233 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 34ms/epoch - 8ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.3688 - accuracy: 0.9484 - f1_m: 0.9563 - precision_m: 0.9659 - recall_m: 0.9474 - val_loss: 0.6248 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 34ms/epoch - 9ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.3672 - accuracy: 0.9484 - f1_m: 0.9537 - precision_m: 0.9652 - recall_m: 0.9431 - val_loss: 0.6321 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 42ms/epoch - 10ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.3655 - accuracy: 0.9513 - f1_m: 0.9571 - precision_m: 0.9601 - recall_m: 0.9547 - val_loss: 0.6320 - val_accuracy: 0.8409 - val_f1_m: 0.8478 - val_precision_m: 0.9286 - val_recall_m: 0.7800 - 33ms/epoch - 8ms/step\n",
            "Accuracy: 84.09\n",
            "f1_score\n",
            "0.8485817313194275\n",
            "45\n",
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.7299 - accuracy: 0.6086 - f1_m: 0.6704 - precision_m: 0.6202 - recall_m: 0.7346 - val_loss: 0.7223 - val_accuracy: 0.6782 - val_f1_m: 0.7083 - val_precision_m: 0.6939 - val_recall_m: 0.7234 - 1s/epoch - 264ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7217 - accuracy: 0.6543 - f1_m: 0.7122 - precision_m: 0.6588 - recall_m: 0.7819 - val_loss: 0.7149 - val_accuracy: 0.7126 - val_f1_m: 0.7423 - val_precision_m: 0.7200 - val_recall_m: 0.7660 - 33ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7130 - accuracy: 0.6943 - f1_m: 0.7389 - precision_m: 0.6680 - recall_m: 0.8361 - val_loss: 0.7077 - val_accuracy: 0.7126 - val_f1_m: 0.7423 - val_precision_m: 0.7200 - val_recall_m: 0.7660 - 32ms/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7047 - accuracy: 0.7229 - f1_m: 0.7552 - precision_m: 0.6692 - recall_m: 0.8786 - val_loss: 0.6995 - val_accuracy: 0.7471 - val_f1_m: 0.7800 - val_precision_m: 0.7358 - val_recall_m: 0.8298 - 32ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.6942 - accuracy: 0.7514 - f1_m: 0.7989 - precision_m: 0.7145 - recall_m: 0.9065 - val_loss: 0.6899 - val_accuracy: 0.7586 - val_f1_m: 0.7921 - val_precision_m: 0.7407 - val_recall_m: 0.8511 - 33ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.6839 - accuracy: 0.7571 - f1_m: 0.7951 - precision_m: 0.7254 - recall_m: 0.8877 - val_loss: 0.6790 - val_accuracy: 0.7701 - val_f1_m: 0.8000 - val_precision_m: 0.7547 - val_recall_m: 0.8511 - 33ms/epoch - 8ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.6717 - accuracy: 0.7743 - f1_m: 0.8105 - precision_m: 0.7434 - recall_m: 0.8917 - val_loss: 0.6666 - val_accuracy: 0.8046 - val_f1_m: 0.8317 - val_precision_m: 0.7778 - val_recall_m: 0.8936 - 34ms/epoch - 8ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.6588 - accuracy: 0.7943 - f1_m: 0.8161 - precision_m: 0.7537 - recall_m: 0.8940 - val_loss: 0.6518 - val_accuracy: 0.8391 - val_f1_m: 0.8571 - val_precision_m: 0.8235 - val_recall_m: 0.8936 - 42ms/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.6426 - accuracy: 0.8171 - f1_m: 0.8381 - precision_m: 0.8058 - recall_m: 0.8753 - val_loss: 0.6351 - val_accuracy: 0.8621 - val_f1_m: 0.8750 - val_precision_m: 0.8571 - val_recall_m: 0.8936 - 35ms/epoch - 9ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.6246 - accuracy: 0.8400 - f1_m: 0.8527 - precision_m: 0.8637 - recall_m: 0.8482 - val_loss: 0.6167 - val_accuracy: 0.8851 - val_f1_m: 0.8936 - val_precision_m: 0.8936 - val_recall_m: 0.8936 - 35ms/epoch - 9ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.6048 - accuracy: 0.8514 - f1_m: 0.8578 - precision_m: 0.8739 - recall_m: 0.8427 - val_loss: 0.5976 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8913 - val_recall_m: 0.8723 - 37ms/epoch - 9ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.5834 - accuracy: 0.8543 - f1_m: 0.8698 - precision_m: 0.8857 - recall_m: 0.8567 - val_loss: 0.5771 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8913 - val_recall_m: 0.8723 - 36ms/epoch - 9ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.5616 - accuracy: 0.8543 - f1_m: 0.8621 - precision_m: 0.8807 - recall_m: 0.8448 - val_loss: 0.5556 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8913 - val_recall_m: 0.8723 - 35ms/epoch - 9ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.5385 - accuracy: 0.8543 - f1_m: 0.8607 - precision_m: 0.8821 - recall_m: 0.8404 - val_loss: 0.5330 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8913 - val_recall_m: 0.8723 - 39ms/epoch - 10ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.5132 - accuracy: 0.8571 - f1_m: 0.8731 - precision_m: 0.8988 - recall_m: 0.8490 - val_loss: 0.5102 - val_accuracy: 0.8736 - val_f1_m: 0.8791 - val_precision_m: 0.9091 - val_recall_m: 0.8511 - 48ms/epoch - 12ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.4887 - accuracy: 0.8686 - f1_m: 0.8679 - precision_m: 0.9244 - recall_m: 0.8231 - val_loss: 0.4881 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 35ms/epoch - 9ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.4635 - accuracy: 0.8714 - f1_m: 0.8730 - precision_m: 0.9234 - recall_m: 0.8289 - val_loss: 0.4661 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 35ms/epoch - 9ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.4406 - accuracy: 0.8771 - f1_m: 0.8684 - precision_m: 0.9290 - recall_m: 0.8163 - val_loss: 0.4456 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 35ms/epoch - 9ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.4187 - accuracy: 0.8771 - f1_m: 0.8785 - precision_m: 0.9335 - recall_m: 0.8297 - val_loss: 0.4281 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.4014 - accuracy: 0.8743 - f1_m: 0.8716 - precision_m: 0.9422 - recall_m: 0.8150 - val_loss: 0.4139 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.3853 - accuracy: 0.8714 - f1_m: 0.8797 - precision_m: 0.9353 - recall_m: 0.8319 - val_loss: 0.4025 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 40ms/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.3734 - accuracy: 0.8743 - f1_m: 0.8763 - precision_m: 0.9371 - recall_m: 0.8250 - val_loss: 0.3946 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 34ms/epoch - 9ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.3646 - accuracy: 0.8771 - f1_m: 0.8681 - precision_m: 0.9537 - recall_m: 0.8012 - val_loss: 0.3897 - val_accuracy: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.9250 - val_recall_m: 0.7872 - 34ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.3567 - accuracy: 0.8743 - f1_m: 0.8638 - precision_m: 0.9438 - recall_m: 0.7979 - val_loss: 0.3858 - val_accuracy: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.9250 - val_recall_m: 0.7872 - 42ms/epoch - 11ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.3522 - accuracy: 0.8771 - f1_m: 0.8817 - precision_m: 0.9445 - recall_m: 0.8316 - val_loss: 0.3822 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 34ms/epoch - 9ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.3468 - accuracy: 0.8771 - f1_m: 0.8737 - precision_m: 0.9441 - recall_m: 0.8132 - val_loss: 0.3805 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 39ms/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.3431 - accuracy: 0.8771 - f1_m: 0.8814 - precision_m: 0.9460 - recall_m: 0.8256 - val_loss: 0.3799 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.3395 - accuracy: 0.8800 - f1_m: 0.8853 - precision_m: 0.9519 - recall_m: 0.8278 - val_loss: 0.3795 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 43ms/epoch - 11ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.3365 - accuracy: 0.8829 - f1_m: 0.8779 - precision_m: 0.9473 - recall_m: 0.8197 - val_loss: 0.3809 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 40ms/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.3344 - accuracy: 0.8829 - f1_m: 0.8779 - precision_m: 0.9501 - recall_m: 0.8196 - val_loss: 0.3818 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.3313 - accuracy: 0.8829 - f1_m: 0.8877 - precision_m: 0.9490 - recall_m: 0.8362 - val_loss: 0.3818 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 37ms/epoch - 9ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.3289 - accuracy: 0.8857 - f1_m: 0.8870 - precision_m: 0.9413 - recall_m: 0.8394 - val_loss: 0.3818 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 39ms/epoch - 10ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.3272 - accuracy: 0.8857 - f1_m: 0.8853 - precision_m: 0.9412 - recall_m: 0.8382 - val_loss: 0.3813 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 39ms/epoch - 10ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.3246 - accuracy: 0.8857 - f1_m: 0.8754 - precision_m: 0.9445 - recall_m: 0.8182 - val_loss: 0.3822 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 37ms/epoch - 9ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.3223 - accuracy: 0.8886 - f1_m: 0.8829 - precision_m: 0.9439 - recall_m: 0.8301 - val_loss: 0.3827 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 37ms/epoch - 9ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.3204 - accuracy: 0.8886 - f1_m: 0.8894 - precision_m: 0.9575 - recall_m: 0.8330 - val_loss: 0.3813 - val_accuracy: 0.8736 - val_f1_m: 0.8764 - val_precision_m: 0.9286 - val_recall_m: 0.8298 - 37ms/epoch - 9ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.3177 - accuracy: 0.8857 - f1_m: 0.8819 - precision_m: 0.9520 - recall_m: 0.8241 - val_loss: 0.3790 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.3155 - accuracy: 0.8943 - f1_m: 0.8873 - precision_m: 0.9420 - recall_m: 0.8393 - val_loss: 0.3769 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 32ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.3141 - accuracy: 0.8943 - f1_m: 0.8875 - precision_m: 0.9332 - recall_m: 0.8463 - val_loss: 0.3759 - val_accuracy: 0.8506 - val_f1_m: 0.8571 - val_precision_m: 0.8864 - val_recall_m: 0.8298 - 49ms/epoch - 12ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.3122 - accuracy: 0.8943 - f1_m: 0.8992 - precision_m: 0.9477 - recall_m: 0.8565 - val_loss: 0.3758 - val_accuracy: 0.8506 - val_f1_m: 0.8571 - val_precision_m: 0.8864 - val_recall_m: 0.8298 - 32ms/epoch - 8ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.3099 - accuracy: 0.8943 - f1_m: 0.8971 - precision_m: 0.9478 - recall_m: 0.8551 - val_loss: 0.3764 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.9070 - val_recall_m: 0.8298 - 36ms/epoch - 9ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.3074 - accuracy: 0.8943 - f1_m: 0.8939 - precision_m: 0.9434 - recall_m: 0.8497 - val_loss: 0.3779 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 34ms/epoch - 8ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.3054 - accuracy: 0.8971 - f1_m: 0.9011 - precision_m: 0.9527 - recall_m: 0.8554 - val_loss: 0.3793 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 39ms/epoch - 10ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.3030 - accuracy: 0.8971 - f1_m: 0.8911 - precision_m: 0.9513 - recall_m: 0.8399 - val_loss: 0.3799 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.3008 - accuracy: 0.8971 - f1_m: 0.9015 - precision_m: 0.9528 - recall_m: 0.8558 - val_loss: 0.3808 - val_accuracy: 0.8506 - val_f1_m: 0.8571 - val_precision_m: 0.8864 - val_recall_m: 0.8298 - 38ms/epoch - 10ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.2987 - accuracy: 0.9000 - f1_m: 0.9113 - precision_m: 0.9476 - recall_m: 0.8789 - val_loss: 0.3817 - val_accuracy: 0.8506 - val_f1_m: 0.8571 - val_precision_m: 0.8864 - val_recall_m: 0.8298 - 35ms/epoch - 9ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.2964 - accuracy: 0.9029 - f1_m: 0.9025 - precision_m: 0.9495 - recall_m: 0.8622 - val_loss: 0.3841 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.2945 - accuracy: 0.9029 - f1_m: 0.9087 - precision_m: 0.9556 - recall_m: 0.8678 - val_loss: 0.3861 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 34ms/epoch - 8ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.2924 - accuracy: 0.9057 - f1_m: 0.9080 - precision_m: 0.9610 - recall_m: 0.8627 - val_loss: 0.3880 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.2911 - accuracy: 0.9057 - f1_m: 0.9090 - precision_m: 0.9483 - recall_m: 0.8737 - val_loss: 0.3882 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 41ms/epoch - 10ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.2880 - accuracy: 0.9057 - f1_m: 0.9140 - precision_m: 0.9592 - recall_m: 0.8732 - val_loss: 0.3911 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.2862 - accuracy: 0.9057 - f1_m: 0.9053 - precision_m: 0.9543 - recall_m: 0.8623 - val_loss: 0.3933 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.2843 - accuracy: 0.9057 - f1_m: 0.9118 - precision_m: 0.9543 - recall_m: 0.8737 - val_loss: 0.3941 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.2823 - accuracy: 0.9114 - f1_m: 0.9141 - precision_m: 0.9489 - recall_m: 0.8831 - val_loss: 0.3953 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 37ms/epoch - 9ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.2795 - accuracy: 0.9086 - f1_m: 0.9170 - precision_m: 0.9592 - recall_m: 0.8802 - val_loss: 0.3986 - val_accuracy: 0.8621 - val_f1_m: 0.8636 - val_precision_m: 0.9268 - val_recall_m: 0.8085 - 38ms/epoch - 9ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.2785 - accuracy: 0.9086 - f1_m: 0.9159 - precision_m: 0.9598 - recall_m: 0.8760 - val_loss: 0.3989 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.2760 - accuracy: 0.9086 - f1_m: 0.9145 - precision_m: 0.9589 - recall_m: 0.8744 - val_loss: 0.4006 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.2747 - accuracy: 0.9086 - f1_m: 0.8920 - precision_m: 0.9499 - recall_m: 0.8491 - val_loss: 0.4000 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 32ms/epoch - 8ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.2722 - accuracy: 0.9057 - f1_m: 0.9126 - precision_m: 0.9350 - recall_m: 0.8925 - val_loss: 0.4006 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 34ms/epoch - 9ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.2702 - accuracy: 0.9057 - f1_m: 0.9112 - precision_m: 0.9349 - recall_m: 0.8898 - val_loss: 0.4037 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 39ms/epoch - 10ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.2685 - accuracy: 0.9114 - f1_m: 0.9161 - precision_m: 0.9549 - recall_m: 0.8817 - val_loss: 0.4092 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 39ms/epoch - 10ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.2672 - accuracy: 0.9114 - f1_m: 0.9064 - precision_m: 0.9557 - recall_m: 0.8626 - val_loss: 0.4111 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 38ms/epoch - 10ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.2635 - accuracy: 0.9114 - f1_m: 0.9146 - precision_m: 0.9629 - recall_m: 0.8724 - val_loss: 0.4114 - val_accuracy: 0.8276 - val_f1_m: 0.8421 - val_precision_m: 0.8333 - val_recall_m: 0.8511 - 37ms/epoch - 9ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.2641 - accuracy: 0.9114 - f1_m: 0.9175 - precision_m: 0.9402 - recall_m: 0.8961 - val_loss: 0.4136 - val_accuracy: 0.8276 - val_f1_m: 0.8421 - val_precision_m: 0.8333 - val_recall_m: 0.8511 - 32ms/epoch - 8ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.2621 - accuracy: 0.9114 - f1_m: 0.9145 - precision_m: 0.9348 - recall_m: 0.8968 - val_loss: 0.4157 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 39ms/epoch - 10ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.2597 - accuracy: 0.9114 - f1_m: 0.9098 - precision_m: 0.9471 - recall_m: 0.8775 - val_loss: 0.4201 - val_accuracy: 0.8506 - val_f1_m: 0.8539 - val_precision_m: 0.9048 - val_recall_m: 0.8085 - 37ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.2580 - accuracy: 0.9143 - f1_m: 0.9196 - precision_m: 0.9657 - recall_m: 0.8780 - val_loss: 0.4196 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.2554 - accuracy: 0.9171 - f1_m: 0.9102 - precision_m: 0.9427 - recall_m: 0.8804 - val_loss: 0.4187 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.2538 - accuracy: 0.9200 - f1_m: 0.9239 - precision_m: 0.9515 - recall_m: 0.8980 - val_loss: 0.4211 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.2517 - accuracy: 0.9200 - f1_m: 0.9212 - precision_m: 0.9509 - recall_m: 0.8937 - val_loss: 0.4242 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 36ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.2506 - accuracy: 0.9229 - f1_m: 0.9272 - precision_m: 0.9515 - recall_m: 0.9049 - val_loss: 0.4264 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 34ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.2480 - accuracy: 0.9229 - f1_m: 0.9270 - precision_m: 0.9450 - recall_m: 0.9122 - val_loss: 0.4291 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 38ms/epoch - 9ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.2478 - accuracy: 0.9200 - f1_m: 0.9201 - precision_m: 0.9522 - recall_m: 0.8924 - val_loss: 0.4322 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.2439 - accuracy: 0.9229 - f1_m: 0.9055 - precision_m: 0.9489 - recall_m: 0.8744 - val_loss: 0.4315 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 34ms/epoch - 9ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.2470 - accuracy: 0.9229 - f1_m: 0.9309 - precision_m: 0.9511 - recall_m: 0.9137 - val_loss: 0.4330 - val_accuracy: 0.8391 - val_f1_m: 0.8511 - val_precision_m: 0.8511 - val_recall_m: 0.8511 - 36ms/epoch - 9ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.2453 - accuracy: 0.9200 - f1_m: 0.9230 - precision_m: 0.9430 - recall_m: 0.9042 - val_loss: 0.4350 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 32ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.2411 - accuracy: 0.9229 - f1_m: 0.9286 - precision_m: 0.9562 - recall_m: 0.9030 - val_loss: 0.4381 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 44ms/epoch - 11ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.2394 - accuracy: 0.9229 - f1_m: 0.9251 - precision_m: 0.9619 - recall_m: 0.8922 - val_loss: 0.4381 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 41ms/epoch - 10ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.2365 - accuracy: 0.9257 - f1_m: 0.9308 - precision_m: 0.9597 - recall_m: 0.9040 - val_loss: 0.4382 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 40ms/epoch - 10ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.2378 - accuracy: 0.9200 - f1_m: 0.9167 - precision_m: 0.9304 - recall_m: 0.9085 - val_loss: 0.4390 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.2380 - accuracy: 0.9257 - f1_m: 0.9290 - precision_m: 0.9580 - recall_m: 0.9029 - val_loss: 0.4413 - val_accuracy: 0.8391 - val_f1_m: 0.8444 - val_precision_m: 0.8837 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.2323 - accuracy: 0.9257 - f1_m: 0.9261 - precision_m: 0.9559 - recall_m: 0.8993 - val_loss: 0.4422 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 33ms/epoch - 8ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.2307 - accuracy: 0.9286 - f1_m: 0.9260 - precision_m: 0.9598 - recall_m: 0.8983 - val_loss: 0.4455 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 42ms/epoch - 11ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.2291 - accuracy: 0.9286 - f1_m: 0.9246 - precision_m: 0.9442 - recall_m: 0.9070 - val_loss: 0.4476 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 34ms/epoch - 8ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.2276 - accuracy: 0.9286 - f1_m: 0.9285 - precision_m: 0.9482 - recall_m: 0.9106 - val_loss: 0.4481 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.2255 - accuracy: 0.9286 - f1_m: 0.9351 - precision_m: 0.9515 - recall_m: 0.9197 - val_loss: 0.4499 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 41ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.2248 - accuracy: 0.9314 - f1_m: 0.9326 - precision_m: 0.9626 - recall_m: 0.9056 - val_loss: 0.4532 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 31ms/epoch - 8ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.2229 - accuracy: 0.9314 - f1_m: 0.9291 - precision_m: 0.9468 - recall_m: 0.9129 - val_loss: 0.4544 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 36ms/epoch - 9ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.2217 - accuracy: 0.9314 - f1_m: 0.9367 - precision_m: 0.9601 - recall_m: 0.9156 - val_loss: 0.4571 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.2202 - accuracy: 0.9314 - f1_m: 0.9316 - precision_m: 0.9563 - recall_m: 0.9090 - val_loss: 0.4584 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 37ms/epoch - 9ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.2185 - accuracy: 0.9314 - f1_m: 0.9346 - precision_m: 0.9585 - recall_m: 0.9141 - val_loss: 0.4604 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 35ms/epoch - 9ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.2168 - accuracy: 0.9343 - f1_m: 0.9353 - precision_m: 0.9644 - recall_m: 0.9086 - val_loss: 0.4635 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 37ms/epoch - 9ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.2155 - accuracy: 0.9343 - f1_m: 0.9388 - precision_m: 0.9618 - recall_m: 0.9171 - val_loss: 0.4661 - val_accuracy: 0.8161 - val_f1_m: 0.8261 - val_precision_m: 0.8444 - val_recall_m: 0.8085 - 32ms/epoch - 8ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.2144 - accuracy: 0.9343 - f1_m: 0.9435 - precision_m: 0.9688 - recall_m: 0.9202 - val_loss: 0.4684 - val_accuracy: 0.8276 - val_f1_m: 0.8387 - val_precision_m: 0.8478 - val_recall_m: 0.8298 - 33ms/epoch - 8ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.2130 - accuracy: 0.9343 - f1_m: 0.9369 - precision_m: 0.9593 - recall_m: 0.9160 - val_loss: 0.4722 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 32ms/epoch - 8ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.2118 - accuracy: 0.9343 - f1_m: 0.9287 - precision_m: 0.9544 - recall_m: 0.9051 - val_loss: 0.4769 - val_accuracy: 0.8161 - val_f1_m: 0.8222 - val_precision_m: 0.8605 - val_recall_m: 0.7872 - 32ms/epoch - 8ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.2102 - accuracy: 0.9343 - f1_m: 0.9455 - precision_m: 0.9662 - recall_m: 0.9263 - val_loss: 0.4780 - val_accuracy: 0.8161 - val_f1_m: 0.8222 - val_precision_m: 0.8605 - val_recall_m: 0.7872 - 37ms/epoch - 9ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.2083 - accuracy: 0.9343 - f1_m: 0.9335 - precision_m: 0.9605 - recall_m: 0.9084 - val_loss: 0.4793 - val_accuracy: 0.8391 - val_f1_m: 0.8478 - val_precision_m: 0.8667 - val_recall_m: 0.8298 - 31ms/epoch - 8ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.2076 - accuracy: 0.9314 - f1_m: 0.9256 - precision_m: 0.9408 - recall_m: 0.9123 - val_loss: 0.4813 - val_accuracy: 0.8276 - val_f1_m: 0.8352 - val_precision_m: 0.8636 - val_recall_m: 0.8085 - 34ms/epoch - 9ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.2070 - accuracy: 0.9343 - f1_m: 0.9344 - precision_m: 0.9548 - recall_m: 0.9154 - val_loss: 0.4830 - val_accuracy: 0.8161 - val_f1_m: 0.8222 - val_precision_m: 0.8605 - val_recall_m: 0.7872 - 33ms/epoch - 8ms/step\n",
            "Accuracy: 81.61\n",
            "f1_score\n",
            "0.8042734265327454\n",
            "45\n",
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.7438 - accuracy: 0.4657 - f1_m: 0.0571 - precision_m: 0.4167 - recall_m: 0.0308 - val_loss: 0.7442 - val_accuracy: 0.5057 - val_f1_m: 0.1224 - val_precision_m: 1.0000 - val_recall_m: 0.0652 - 1s/epoch - 259ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7380 - accuracy: 0.4829 - f1_m: 0.1224 - precision_m: 0.7500 - recall_m: 0.0667 - val_loss: 0.7402 - val_accuracy: 0.5057 - val_f1_m: 0.1569 - val_precision_m: 0.8000 - val_recall_m: 0.0870 - 32ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7341 - accuracy: 0.5143 - f1_m: 0.2225 - precision_m: 0.7229 - recall_m: 0.1316 - val_loss: 0.7364 - val_accuracy: 0.4828 - val_f1_m: 0.1818 - val_precision_m: 0.5556 - val_recall_m: 0.1087 - 36ms/epoch - 9ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7305 - accuracy: 0.5371 - f1_m: 0.2774 - precision_m: 0.7600 - recall_m: 0.1731 - val_loss: 0.7323 - val_accuracy: 0.4713 - val_f1_m: 0.2581 - val_precision_m: 0.5000 - val_recall_m: 0.1739 - 32ms/epoch - 8ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.7264 - accuracy: 0.5686 - f1_m: 0.3823 - precision_m: 0.7780 - recall_m: 0.2567 - val_loss: 0.7282 - val_accuracy: 0.5632 - val_f1_m: 0.4412 - val_precision_m: 0.6818 - val_recall_m: 0.3261 - 36ms/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.7221 - accuracy: 0.6371 - f1_m: 0.5529 - precision_m: 0.8610 - recall_m: 0.4117 - val_loss: 0.7240 - val_accuracy: 0.6322 - val_f1_m: 0.5676 - val_precision_m: 0.7500 - val_recall_m: 0.4565 - 38ms/epoch - 9ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.7175 - accuracy: 0.6829 - f1_m: 0.6199 - precision_m: 0.8578 - recall_m: 0.4906 - val_loss: 0.7199 - val_accuracy: 0.6437 - val_f1_m: 0.6076 - val_precision_m: 0.7273 - val_recall_m: 0.5217 - 35ms/epoch - 9ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.7128 - accuracy: 0.7171 - f1_m: 0.6835 - precision_m: 0.8920 - recall_m: 0.5553 - val_loss: 0.7157 - val_accuracy: 0.6897 - val_f1_m: 0.6824 - val_precision_m: 0.7436 - val_recall_m: 0.6304 - 38ms/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.7077 - accuracy: 0.7229 - f1_m: 0.6754 - precision_m: 0.8540 - recall_m: 0.5590 - val_loss: 0.7108 - val_accuracy: 0.7011 - val_f1_m: 0.6829 - val_precision_m: 0.7778 - val_recall_m: 0.6087 - 40ms/epoch - 10ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.7021 - accuracy: 0.7229 - f1_m: 0.6906 - precision_m: 0.8893 - recall_m: 0.5699 - val_loss: 0.7053 - val_accuracy: 0.7241 - val_f1_m: 0.7143 - val_precision_m: 0.7895 - val_recall_m: 0.6522 - 35ms/epoch - 9ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.6964 - accuracy: 0.7286 - f1_m: 0.7068 - precision_m: 0.8910 - recall_m: 0.5880 - val_loss: 0.6996 - val_accuracy: 0.7471 - val_f1_m: 0.7317 - val_precision_m: 0.8333 - val_recall_m: 0.6522 - 36ms/epoch - 9ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.6901 - accuracy: 0.7371 - f1_m: 0.7007 - precision_m: 0.9043 - recall_m: 0.5732 - val_loss: 0.6934 - val_accuracy: 0.7586 - val_f1_m: 0.7407 - val_precision_m: 0.8571 - val_recall_m: 0.6522 - 35ms/epoch - 9ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.6834 - accuracy: 0.7371 - f1_m: 0.6988 - precision_m: 0.8883 - recall_m: 0.5781 - val_loss: 0.6867 - val_accuracy: 0.7816 - val_f1_m: 0.7654 - val_precision_m: 0.8857 - val_recall_m: 0.6739 - 34ms/epoch - 8ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.6758 - accuracy: 0.7486 - f1_m: 0.7113 - precision_m: 0.9176 - recall_m: 0.5844 - val_loss: 0.6792 - val_accuracy: 0.7586 - val_f1_m: 0.7407 - val_precision_m: 0.8571 - val_recall_m: 0.6522 - 37ms/epoch - 9ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.6682 - accuracy: 0.7514 - f1_m: 0.6861 - precision_m: 0.8996 - recall_m: 0.5586 - val_loss: 0.6708 - val_accuracy: 0.7931 - val_f1_m: 0.7857 - val_precision_m: 0.8684 - val_recall_m: 0.7174 - 35ms/epoch - 9ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.6596 - accuracy: 0.7514 - f1_m: 0.7190 - precision_m: 0.9242 - recall_m: 0.5907 - val_loss: 0.6620 - val_accuracy: 0.7931 - val_f1_m: 0.7857 - val_precision_m: 0.8684 - val_recall_m: 0.7174 - 34ms/epoch - 9ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.6508 - accuracy: 0.7714 - f1_m: 0.7459 - precision_m: 0.9232 - recall_m: 0.6284 - val_loss: 0.6523 - val_accuracy: 0.8046 - val_f1_m: 0.8000 - val_precision_m: 0.8718 - val_recall_m: 0.7391 - 39ms/epoch - 10ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.6420 - accuracy: 0.7857 - f1_m: 0.7660 - precision_m: 0.9262 - recall_m: 0.6551 - val_loss: 0.6421 - val_accuracy: 0.8161 - val_f1_m: 0.8095 - val_precision_m: 0.8947 - val_recall_m: 0.7391 - 46ms/epoch - 12ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.6319 - accuracy: 0.7943 - f1_m: 0.7659 - precision_m: 0.9420 - recall_m: 0.6512 - val_loss: 0.6320 - val_accuracy: 0.8161 - val_f1_m: 0.8095 - val_precision_m: 0.8947 - val_recall_m: 0.7391 - 33ms/epoch - 8ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.6221 - accuracy: 0.8057 - f1_m: 0.7748 - precision_m: 0.9162 - recall_m: 0.6723 - val_loss: 0.6215 - val_accuracy: 0.8276 - val_f1_m: 0.8235 - val_precision_m: 0.8974 - val_recall_m: 0.7609 - 37ms/epoch - 9ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.6118 - accuracy: 0.8086 - f1_m: 0.8033 - precision_m: 0.9294 - recall_m: 0.7104 - val_loss: 0.6105 - val_accuracy: 0.8276 - val_f1_m: 0.8235 - val_precision_m: 0.8974 - val_recall_m: 0.7609 - 42ms/epoch - 10ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.6013 - accuracy: 0.8229 - f1_m: 0.8079 - precision_m: 0.9483 - recall_m: 0.7038 - val_loss: 0.5993 - val_accuracy: 0.8276 - val_f1_m: 0.8235 - val_precision_m: 0.8974 - val_recall_m: 0.7609 - 40ms/epoch - 10ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.5906 - accuracy: 0.8314 - f1_m: 0.8056 - precision_m: 0.9460 - recall_m: 0.7031 - val_loss: 0.5876 - val_accuracy: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.9024 - val_recall_m: 0.8043 - 32ms/epoch - 8ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.5798 - accuracy: 0.8371 - f1_m: 0.8288 - precision_m: 0.9552 - recall_m: 0.7361 - val_loss: 0.5755 - val_accuracy: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.9024 - val_recall_m: 0.8043 - 34ms/epoch - 9ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.5684 - accuracy: 0.8371 - f1_m: 0.8270 - precision_m: 0.9586 - recall_m: 0.7298 - val_loss: 0.5642 - val_accuracy: 0.8391 - val_f1_m: 0.8409 - val_precision_m: 0.8810 - val_recall_m: 0.8043 - 32ms/epoch - 8ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.5565 - accuracy: 0.8429 - f1_m: 0.8269 - precision_m: 0.9474 - recall_m: 0.7346 - val_loss: 0.5527 - val_accuracy: 0.8621 - val_f1_m: 0.8667 - val_precision_m: 0.8864 - val_recall_m: 0.8478 - 32ms/epoch - 8ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.5450 - accuracy: 0.8457 - f1_m: 0.8294 - precision_m: 0.9450 - recall_m: 0.7395 - val_loss: 0.5409 - val_accuracy: 0.8851 - val_f1_m: 0.8913 - val_precision_m: 0.8913 - val_recall_m: 0.8913 - 31ms/epoch - 8ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.5323 - accuracy: 0.8486 - f1_m: 0.8201 - precision_m: 0.9276 - recall_m: 0.7383 - val_loss: 0.5287 - val_accuracy: 0.8851 - val_f1_m: 0.8913 - val_precision_m: 0.8913 - val_recall_m: 0.8913 - 36ms/epoch - 9ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.5191 - accuracy: 0.8629 - f1_m: 0.8641 - precision_m: 0.9552 - recall_m: 0.7900 - val_loss: 0.5152 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8723 - val_recall_m: 0.8913 - 39ms/epoch - 10ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.5061 - accuracy: 0.8714 - f1_m: 0.8609 - precision_m: 0.9562 - recall_m: 0.7904 - val_loss: 0.5021 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8723 - val_recall_m: 0.8913 - 35ms/epoch - 9ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.4922 - accuracy: 0.8714 - f1_m: 0.8586 - precision_m: 0.9505 - recall_m: 0.7877 - val_loss: 0.4885 - val_accuracy: 0.8966 - val_f1_m: 0.9053 - val_precision_m: 0.8776 - val_recall_m: 0.9348 - 40ms/epoch - 10ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.4773 - accuracy: 0.8800 - f1_m: 0.8817 - precision_m: 0.9566 - recall_m: 0.8202 - val_loss: 0.4796 - val_accuracy: 0.8621 - val_f1_m: 0.8776 - val_precision_m: 0.8269 - val_recall_m: 0.9348 - 38ms/epoch - 10ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.4637 - accuracy: 0.8829 - f1_m: 0.8840 - precision_m: 0.9424 - recall_m: 0.8327 - val_loss: 0.4714 - val_accuracy: 0.8736 - val_f1_m: 0.8889 - val_precision_m: 0.8302 - val_recall_m: 0.9565 - 38ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.4492 - accuracy: 0.8829 - f1_m: 0.8872 - precision_m: 0.9364 - recall_m: 0.8465 - val_loss: 0.4583 - val_accuracy: 0.8736 - val_f1_m: 0.8889 - val_precision_m: 0.8302 - val_recall_m: 0.9565 - 40ms/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.4337 - accuracy: 0.8886 - f1_m: 0.8875 - precision_m: 0.9252 - recall_m: 0.8537 - val_loss: 0.4401 - val_accuracy: 0.8736 - val_f1_m: 0.8889 - val_precision_m: 0.8302 - val_recall_m: 0.9565 - 30ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.4182 - accuracy: 0.8914 - f1_m: 0.8927 - precision_m: 0.9477 - recall_m: 0.8449 - val_loss: 0.4274 - val_accuracy: 0.8621 - val_f1_m: 0.8776 - val_precision_m: 0.8269 - val_recall_m: 0.9348 - 34ms/epoch - 8ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.4036 - accuracy: 0.8886 - f1_m: 0.8962 - precision_m: 0.9432 - recall_m: 0.8548 - val_loss: 0.4173 - val_accuracy: 0.8736 - val_f1_m: 0.8889 - val_precision_m: 0.8302 - val_recall_m: 0.9565 - 36ms/epoch - 9ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.3899 - accuracy: 0.8943 - f1_m: 0.8873 - precision_m: 0.9414 - recall_m: 0.8410 - val_loss: 0.4099 - val_accuracy: 0.8736 - val_f1_m: 0.8889 - val_precision_m: 0.8302 - val_recall_m: 0.9565 - 34ms/epoch - 9ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.3761 - accuracy: 0.8914 - f1_m: 0.8977 - precision_m: 0.9385 - recall_m: 0.8614 - val_loss: 0.4034 - val_accuracy: 0.8621 - val_f1_m: 0.8800 - val_precision_m: 0.8148 - val_recall_m: 0.9565 - 33ms/epoch - 8ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.3641 - accuracy: 0.8886 - f1_m: 0.8933 - precision_m: 0.9339 - recall_m: 0.8573 - val_loss: 0.4017 - val_accuracy: 0.8621 - val_f1_m: 0.8800 - val_precision_m: 0.8148 - val_recall_m: 0.9565 - 32ms/epoch - 8ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.3531 - accuracy: 0.8886 - f1_m: 0.8861 - precision_m: 0.9221 - recall_m: 0.8541 - val_loss: 0.3945 - val_accuracy: 0.8506 - val_f1_m: 0.8687 - val_precision_m: 0.8113 - val_recall_m: 0.9348 - 35ms/epoch - 9ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.3429 - accuracy: 0.8857 - f1_m: 0.8880 - precision_m: 0.9170 - recall_m: 0.8634 - val_loss: 0.3906 - val_accuracy: 0.8506 - val_f1_m: 0.8687 - val_precision_m: 0.8113 - val_recall_m: 0.9348 - 46ms/epoch - 11ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.3336 - accuracy: 0.8886 - f1_m: 0.8964 - precision_m: 0.9368 - recall_m: 0.8598 - val_loss: 0.3892 - val_accuracy: 0.8506 - val_f1_m: 0.8687 - val_precision_m: 0.8113 - val_recall_m: 0.9348 - 34ms/epoch - 8ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.3262 - accuracy: 0.8914 - f1_m: 0.8971 - precision_m: 0.9362 - recall_m: 0.8632 - val_loss: 0.3891 - val_accuracy: 0.8506 - val_f1_m: 0.8687 - val_precision_m: 0.8113 - val_recall_m: 0.9348 - 34ms/epoch - 9ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.3198 - accuracy: 0.8914 - f1_m: 0.8976 - precision_m: 0.9303 - recall_m: 0.8683 - val_loss: 0.3972 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 43ms/epoch - 11ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.3147 - accuracy: 0.8914 - f1_m: 0.8976 - precision_m: 0.9228 - recall_m: 0.8741 - val_loss: 0.4038 - val_accuracy: 0.8506 - val_f1_m: 0.8713 - val_precision_m: 0.8000 - val_recall_m: 0.9565 - 35ms/epoch - 9ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.3092 - accuracy: 0.8943 - f1_m: 0.9023 - precision_m: 0.9267 - recall_m: 0.8801 - val_loss: 0.3993 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 35ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.3043 - accuracy: 0.8943 - f1_m: 0.9021 - precision_m: 0.9279 - recall_m: 0.8784 - val_loss: 0.4037 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 37ms/epoch - 9ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.3010 - accuracy: 0.8971 - f1_m: 0.8990 - precision_m: 0.9383 - recall_m: 0.8682 - val_loss: 0.4056 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 38ms/epoch - 10ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.2976 - accuracy: 0.9029 - f1_m: 0.8962 - precision_m: 0.9206 - recall_m: 0.8741 - val_loss: 0.4089 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 42ms/epoch - 10ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.2941 - accuracy: 0.9000 - f1_m: 0.8999 - precision_m: 0.9316 - recall_m: 0.8715 - val_loss: 0.4101 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 44ms/epoch - 11ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.2913 - accuracy: 0.9029 - f1_m: 0.8985 - precision_m: 0.9216 - recall_m: 0.8771 - val_loss: 0.4127 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 36ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.2885 - accuracy: 0.9029 - f1_m: 0.9093 - precision_m: 0.9449 - recall_m: 0.8769 - val_loss: 0.4109 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 44ms/epoch - 11ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.2855 - accuracy: 0.9057 - f1_m: 0.9110 - precision_m: 0.9510 - recall_m: 0.8759 - val_loss: 0.4152 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 41ms/epoch - 10ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.2829 - accuracy: 0.9114 - f1_m: 0.9129 - precision_m: 0.9332 - recall_m: 0.8944 - val_loss: 0.4261 - val_accuracy: 0.8506 - val_f1_m: 0.8713 - val_precision_m: 0.8000 - val_recall_m: 0.9565 - 36ms/epoch - 9ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.2809 - accuracy: 0.9114 - f1_m: 0.9196 - precision_m: 0.9379 - recall_m: 0.9030 - val_loss: 0.4219 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 39ms/epoch - 10ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.2781 - accuracy: 0.9114 - f1_m: 0.9167 - precision_m: 0.9433 - recall_m: 0.8916 - val_loss: 0.4166 - val_accuracy: 0.8391 - val_f1_m: 0.8600 - val_precision_m: 0.7963 - val_recall_m: 0.9348 - 42ms/epoch - 10ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.2762 - accuracy: 0.9086 - f1_m: 0.9081 - precision_m: 0.9374 - recall_m: 0.8807 - val_loss: 0.4233 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 41ms/epoch - 10ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.2734 - accuracy: 0.9086 - f1_m: 0.9212 - precision_m: 0.9468 - recall_m: 0.8972 - val_loss: 0.4255 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 35ms/epoch - 9ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.2709 - accuracy: 0.9086 - f1_m: 0.9060 - precision_m: 0.9342 - recall_m: 0.8797 - val_loss: 0.4257 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 38ms/epoch - 10ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.2693 - accuracy: 0.9114 - f1_m: 0.9150 - precision_m: 0.9369 - recall_m: 0.8976 - val_loss: 0.4296 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 35ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.2671 - accuracy: 0.9086 - f1_m: 0.9103 - precision_m: 0.9306 - recall_m: 0.8924 - val_loss: 0.4303 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 38ms/epoch - 10ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.2662 - accuracy: 0.9086 - f1_m: 0.9197 - precision_m: 0.9371 - recall_m: 0.9073 - val_loss: 0.4343 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 38ms/epoch - 10ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.2632 - accuracy: 0.9171 - f1_m: 0.9240 - precision_m: 0.9383 - recall_m: 0.9117 - val_loss: 0.4290 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 39ms/epoch - 10ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.2614 - accuracy: 0.9143 - f1_m: 0.9199 - precision_m: 0.9523 - recall_m: 0.8909 - val_loss: 0.4386 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 49ms/epoch - 12ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.2589 - accuracy: 0.9171 - f1_m: 0.9193 - precision_m: 0.9382 - recall_m: 0.9015 - val_loss: 0.4428 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 34ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.2572 - accuracy: 0.9200 - f1_m: 0.9242 - precision_m: 0.9342 - recall_m: 0.9155 - val_loss: 0.4501 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 39ms/epoch - 10ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.2556 - accuracy: 0.9229 - f1_m: 0.9197 - precision_m: 0.9413 - recall_m: 0.9006 - val_loss: 0.4411 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 36ms/epoch - 9ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.2540 - accuracy: 0.9257 - f1_m: 0.9299 - precision_m: 0.9458 - recall_m: 0.9148 - val_loss: 0.4497 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 34ms/epoch - 9ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.2516 - accuracy: 0.9257 - f1_m: 0.9253 - precision_m: 0.9351 - recall_m: 0.9180 - val_loss: 0.4466 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 35ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.2489 - accuracy: 0.9229 - f1_m: 0.9210 - precision_m: 0.9506 - recall_m: 0.8942 - val_loss: 0.4349 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 33ms/epoch - 8ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.2484 - accuracy: 0.9229 - f1_m: 0.9296 - precision_m: 0.9600 - recall_m: 0.9022 - val_loss: 0.4429 - val_accuracy: 0.8276 - val_f1_m: 0.8515 - val_precision_m: 0.7818 - val_recall_m: 0.9348 - 36ms/epoch - 9ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.2458 - accuracy: 0.9200 - f1_m: 0.9229 - precision_m: 0.9457 - recall_m: 0.9022 - val_loss: 0.4507 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 34ms/epoch - 8ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.2436 - accuracy: 0.9171 - f1_m: 0.9158 - precision_m: 0.9321 - recall_m: 0.9025 - val_loss: 0.4484 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 40ms/epoch - 10ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.2418 - accuracy: 0.9200 - f1_m: 0.9253 - precision_m: 0.9364 - recall_m: 0.9176 - val_loss: 0.4521 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 39ms/epoch - 10ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.2398 - accuracy: 0.9229 - f1_m: 0.9290 - precision_m: 0.9466 - recall_m: 0.9122 - val_loss: 0.4484 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 33ms/epoch - 8ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.2383 - accuracy: 0.9229 - f1_m: 0.9217 - precision_m: 0.9375 - recall_m: 0.9078 - val_loss: 0.4602 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 43ms/epoch - 11ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.2376 - accuracy: 0.9257 - f1_m: 0.9389 - precision_m: 0.9508 - recall_m: 0.9281 - val_loss: 0.4580 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 44ms/epoch - 11ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.2328 - accuracy: 0.9257 - f1_m: 0.9362 - precision_m: 0.9463 - recall_m: 0.9272 - val_loss: 0.4374 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 38ms/epoch - 9ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.2331 - accuracy: 0.9229 - f1_m: 0.9292 - precision_m: 0.9617 - recall_m: 0.9001 - val_loss: 0.4358 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 42ms/epoch - 11ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.2306 - accuracy: 0.9229 - f1_m: 0.9277 - precision_m: 0.9663 - recall_m: 0.8928 - val_loss: 0.4542 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 42ms/epoch - 11ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.2285 - accuracy: 0.9286 - f1_m: 0.9252 - precision_m: 0.9341 - recall_m: 0.9174 - val_loss: 0.4761 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 38ms/epoch - 10ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.2268 - accuracy: 0.9314 - f1_m: 0.9340 - precision_m: 0.9423 - recall_m: 0.9263 - val_loss: 0.4676 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 34ms/epoch - 8ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.2241 - accuracy: 0.9343 - f1_m: 0.9422 - precision_m: 0.9583 - recall_m: 0.9267 - val_loss: 0.4561 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 36ms/epoch - 9ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.2231 - accuracy: 0.9314 - f1_m: 0.9290 - precision_m: 0.9534 - recall_m: 0.9067 - val_loss: 0.4618 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 41ms/epoch - 10ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.2207 - accuracy: 0.9343 - f1_m: 0.9430 - precision_m: 0.9521 - recall_m: 0.9352 - val_loss: 0.4899 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 41ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.2200 - accuracy: 0.9343 - f1_m: 0.9381 - precision_m: 0.9425 - recall_m: 0.9341 - val_loss: 0.4691 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 36ms/epoch - 9ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.2163 - accuracy: 0.9343 - f1_m: 0.9409 - precision_m: 0.9521 - recall_m: 0.9300 - val_loss: 0.4567 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 49ms/epoch - 12ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.2151 - accuracy: 0.9343 - f1_m: 0.9379 - precision_m: 0.9561 - recall_m: 0.9216 - val_loss: 0.4612 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 42ms/epoch - 10ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.2124 - accuracy: 0.9400 - f1_m: 0.9411 - precision_m: 0.9526 - recall_m: 0.9301 - val_loss: 0.4765 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 34ms/epoch - 9ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.2104 - accuracy: 0.9400 - f1_m: 0.9431 - precision_m: 0.9561 - recall_m: 0.9305 - val_loss: 0.4670 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 40ms/epoch - 10ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.2085 - accuracy: 0.9457 - f1_m: 0.9462 - precision_m: 0.9535 - recall_m: 0.9401 - val_loss: 0.4734 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 41ms/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.2046 - accuracy: 0.9457 - f1_m: 0.9450 - precision_m: 0.9480 - recall_m: 0.9429 - val_loss: 0.4633 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 38ms/epoch - 9ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.2019 - accuracy: 0.9429 - f1_m: 0.9496 - precision_m: 0.9610 - recall_m: 0.9388 - val_loss: 0.4536 - val_accuracy: 0.8391 - val_f1_m: 0.8627 - val_precision_m: 0.7857 - val_recall_m: 0.9565 - 35ms/epoch - 9ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.2008 - accuracy: 0.9457 - f1_m: 0.9458 - precision_m: 0.9708 - recall_m: 0.9236 - val_loss: 0.4663 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 40ms/epoch - 10ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.2003 - accuracy: 0.9429 - f1_m: 0.9482 - precision_m: 0.9527 - recall_m: 0.9450 - val_loss: 0.5049 - val_accuracy: 0.8046 - val_f1_m: 0.8381 - val_precision_m: 0.7458 - val_recall_m: 0.9565 - 34ms/epoch - 8ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.1969 - accuracy: 0.9429 - f1_m: 0.9487 - precision_m: 0.9490 - recall_m: 0.9486 - val_loss: 0.4776 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 39ms/epoch - 10ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.1921 - accuracy: 0.9514 - f1_m: 0.9503 - precision_m: 0.9659 - recall_m: 0.9360 - val_loss: 0.4637 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 41ms/epoch - 10ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.1907 - accuracy: 0.9457 - f1_m: 0.9471 - precision_m: 0.9612 - recall_m: 0.9344 - val_loss: 0.4804 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 38ms/epoch - 10ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.1878 - accuracy: 0.9514 - f1_m: 0.9515 - precision_m: 0.9658 - recall_m: 0.9377 - val_loss: 0.4750 - val_accuracy: 0.8276 - val_f1_m: 0.8544 - val_precision_m: 0.7719 - val_recall_m: 0.9565 - 37ms/epoch - 9ms/step\n",
            "Accuracy: 82.76\n",
            "f1_score\n",
            "0.8416776061058044\n",
            "45\n",
            "Epoch 1/100\n",
            "4/4 - 1s - loss: 0.7686 - accuracy: 0.3457 - f1_m: 0.3065 - precision_m: 0.3513 - recall_m: 0.2808 - val_loss: 0.7571 - val_accuracy: 0.3448 - val_f1_m: 0.4124 - val_precision_m: 0.4000 - val_recall_m: 0.4255 - 1s/epoch - 366ms/step\n",
            "Epoch 2/100\n",
            "4/4 - 0s - loss: 0.7501 - accuracy: 0.3943 - f1_m: 0.4483 - precision_m: 0.4348 - recall_m: 0.4726 - val_loss: 0.7431 - val_accuracy: 0.4828 - val_f1_m: 0.5946 - val_precision_m: 0.5156 - val_recall_m: 0.7021 - 34ms/epoch - 8ms/step\n",
            "Epoch 3/100\n",
            "4/4 - 0s - loss: 0.7365 - accuracy: 0.4886 - f1_m: 0.5882 - precision_m: 0.4981 - recall_m: 0.7244 - val_loss: 0.7314 - val_accuracy: 0.5402 - val_f1_m: 0.6721 - val_precision_m: 0.5467 - val_recall_m: 0.8723 - 38ms/epoch - 10ms/step\n",
            "Epoch 4/100\n",
            "4/4 - 0s - loss: 0.7259 - accuracy: 0.5400 - f1_m: 0.6638 - precision_m: 0.5430 - recall_m: 0.8537 - val_loss: 0.7213 - val_accuracy: 0.5632 - val_f1_m: 0.6984 - val_precision_m: 0.5570 - val_recall_m: 0.9362 - 36ms/epoch - 9ms/step\n",
            "Epoch 5/100\n",
            "4/4 - 0s - loss: 0.7163 - accuracy: 0.5800 - f1_m: 0.7095 - precision_m: 0.5763 - recall_m: 0.9247 - val_loss: 0.7125 - val_accuracy: 0.5632 - val_f1_m: 0.7031 - val_precision_m: 0.5556 - val_recall_m: 0.9574 - 38ms/epoch - 9ms/step\n",
            "Epoch 6/100\n",
            "4/4 - 0s - loss: 0.7074 - accuracy: 0.5914 - f1_m: 0.7149 - precision_m: 0.5760 - recall_m: 0.9448 - val_loss: 0.7036 - val_accuracy: 0.5747 - val_f1_m: 0.7132 - val_precision_m: 0.5610 - val_recall_m: 0.9787 - 41ms/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "4/4 - 0s - loss: 0.6987 - accuracy: 0.5943 - f1_m: 0.7216 - precision_m: 0.5726 - recall_m: 0.9762 - val_loss: 0.6941 - val_accuracy: 0.5517 - val_f1_m: 0.7023 - val_precision_m: 0.5476 - val_recall_m: 0.9787 - 38ms/epoch - 9ms/step\n",
            "Epoch 8/100\n",
            "4/4 - 0s - loss: 0.6897 - accuracy: 0.5857 - f1_m: 0.7222 - precision_m: 0.5734 - recall_m: 0.9875 - val_loss: 0.6847 - val_accuracy: 0.5747 - val_f1_m: 0.7132 - val_precision_m: 0.5610 - val_recall_m: 0.9787 - 39ms/epoch - 10ms/step\n",
            "Epoch 9/100\n",
            "4/4 - 0s - loss: 0.6803 - accuracy: 0.5800 - f1_m: 0.7169 - precision_m: 0.5620 - recall_m: 0.9907 - val_loss: 0.6751 - val_accuracy: 0.5862 - val_f1_m: 0.7231 - val_precision_m: 0.5663 - val_recall_m: 1.0000 - 58ms/epoch - 15ms/step\n",
            "Epoch 10/100\n",
            "4/4 - 0s - loss: 0.6701 - accuracy: 0.6000 - f1_m: 0.7297 - precision_m: 0.5796 - recall_m: 0.9899 - val_loss: 0.6650 - val_accuracy: 0.5747 - val_f1_m: 0.7132 - val_precision_m: 0.5610 - val_recall_m: 0.9787 - 41ms/epoch - 10ms/step\n",
            "Epoch 11/100\n",
            "4/4 - 0s - loss: 0.6597 - accuracy: 0.6229 - f1_m: 0.7273 - precision_m: 0.5779 - recall_m: 0.9853 - val_loss: 0.6540 - val_accuracy: 0.6207 - val_f1_m: 0.7360 - val_precision_m: 0.5897 - val_recall_m: 0.9787 - 41ms/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "4/4 - 0s - loss: 0.6477 - accuracy: 0.6429 - f1_m: 0.7346 - precision_m: 0.5872 - recall_m: 0.9845 - val_loss: 0.6415 - val_accuracy: 0.6782 - val_f1_m: 0.7627 - val_precision_m: 0.6338 - val_recall_m: 0.9574 - 41ms/epoch - 10ms/step\n",
            "Epoch 13/100\n",
            "4/4 - 0s - loss: 0.6347 - accuracy: 0.7057 - f1_m: 0.7829 - precision_m: 0.6518 - recall_m: 0.9816 - val_loss: 0.6272 - val_accuracy: 0.7241 - val_f1_m: 0.7895 - val_precision_m: 0.6716 - val_recall_m: 0.9574 - 44ms/epoch - 11ms/step\n",
            "Epoch 14/100\n",
            "4/4 - 0s - loss: 0.6206 - accuracy: 0.7543 - f1_m: 0.8235 - precision_m: 0.7155 - recall_m: 0.9759 - val_loss: 0.6116 - val_accuracy: 0.7816 - val_f1_m: 0.8224 - val_precision_m: 0.7333 - val_recall_m: 0.9362 - 34ms/epoch - 9ms/step\n",
            "Epoch 15/100\n",
            "4/4 - 0s - loss: 0.6049 - accuracy: 0.7829 - f1_m: 0.8254 - precision_m: 0.7256 - recall_m: 0.9591 - val_loss: 0.5948 - val_accuracy: 0.8046 - val_f1_m: 0.8350 - val_precision_m: 0.7679 - val_recall_m: 0.9149 - 33ms/epoch - 8ms/step\n",
            "Epoch 16/100\n",
            "4/4 - 0s - loss: 0.5874 - accuracy: 0.7943 - f1_m: 0.8376 - precision_m: 0.7477 - recall_m: 0.9534 - val_loss: 0.5758 - val_accuracy: 0.8276 - val_f1_m: 0.8485 - val_precision_m: 0.8077 - val_recall_m: 0.8936 - 37ms/epoch - 9ms/step\n",
            "Epoch 17/100\n",
            "4/4 - 0s - loss: 0.5684 - accuracy: 0.8029 - f1_m: 0.8323 - precision_m: 0.7462 - recall_m: 0.9428 - val_loss: 0.5544 - val_accuracy: 0.8736 - val_f1_m: 0.8842 - val_precision_m: 0.8750 - val_recall_m: 0.8936 - 37ms/epoch - 9ms/step\n",
            "Epoch 18/100\n",
            "4/4 - 0s - loss: 0.5492 - accuracy: 0.8086 - f1_m: 0.8313 - precision_m: 0.7692 - recall_m: 0.9073 - val_loss: 0.5291 - val_accuracy: 0.8621 - val_f1_m: 0.8723 - val_precision_m: 0.8723 - val_recall_m: 0.8723 - 37ms/epoch - 9ms/step\n",
            "Epoch 19/100\n",
            "4/4 - 0s - loss: 0.5262 - accuracy: 0.8400 - f1_m: 0.8642 - precision_m: 0.8345 - recall_m: 0.9025 - val_loss: 0.5028 - val_accuracy: 0.8736 - val_f1_m: 0.8817 - val_precision_m: 0.8913 - val_recall_m: 0.8723 - 41ms/epoch - 10ms/step\n",
            "Epoch 20/100\n",
            "4/4 - 0s - loss: 0.5022 - accuracy: 0.8457 - f1_m: 0.8622 - precision_m: 0.8388 - recall_m: 0.8872 - val_loss: 0.4752 - val_accuracy: 0.8506 - val_f1_m: 0.8506 - val_precision_m: 0.9250 - val_recall_m: 0.7872 - 46ms/epoch - 12ms/step\n",
            "Epoch 21/100\n",
            "4/4 - 0s - loss: 0.4766 - accuracy: 0.8629 - f1_m: 0.8663 - precision_m: 0.8654 - recall_m: 0.8701 - val_loss: 0.4487 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 22/100\n",
            "4/4 - 0s - loss: 0.4519 - accuracy: 0.8771 - f1_m: 0.8889 - precision_m: 0.8893 - recall_m: 0.8916 - val_loss: 0.4253 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 34ms/epoch - 8ms/step\n",
            "Epoch 23/100\n",
            "4/4 - 0s - loss: 0.4272 - accuracy: 0.8800 - f1_m: 0.8851 - precision_m: 0.8981 - recall_m: 0.8727 - val_loss: 0.4054 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 24/100\n",
            "4/4 - 0s - loss: 0.4064 - accuracy: 0.8857 - f1_m: 0.8963 - precision_m: 0.9327 - recall_m: 0.8640 - val_loss: 0.3900 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 46ms/epoch - 11ms/step\n",
            "Epoch 25/100\n",
            "4/4 - 0s - loss: 0.3886 - accuracy: 0.8771 - f1_m: 0.8823 - precision_m: 0.9240 - recall_m: 0.8450 - val_loss: 0.3792 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 26/100\n",
            "4/4 - 0s - loss: 0.3764 - accuracy: 0.8743 - f1_m: 0.8741 - precision_m: 0.9242 - recall_m: 0.8306 - val_loss: 0.3722 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 10ms/step\n",
            "Epoch 27/100\n",
            "4/4 - 0s - loss: 0.3662 - accuracy: 0.8714 - f1_m: 0.8754 - precision_m: 0.9153 - recall_m: 0.8400 - val_loss: 0.3660 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 10ms/step\n",
            "Epoch 28/100\n",
            "4/4 - 0s - loss: 0.3580 - accuracy: 0.8743 - f1_m: 0.8774 - precision_m: 0.9221 - recall_m: 0.8374 - val_loss: 0.3662 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 41ms/epoch - 10ms/step\n",
            "Epoch 29/100\n",
            "4/4 - 0s - loss: 0.3537 - accuracy: 0.8743 - f1_m: 0.8727 - precision_m: 0.9332 - recall_m: 0.8259 - val_loss: 0.3664 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 9ms/step\n",
            "Epoch 30/100\n",
            "4/4 - 0s - loss: 0.3476 - accuracy: 0.8743 - f1_m: 0.8630 - precision_m: 0.9118 - recall_m: 0.8196 - val_loss: 0.3600 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 57ms/epoch - 14ms/step\n",
            "Epoch 31/100\n",
            "4/4 - 0s - loss: 0.3449 - accuracy: 0.8800 - f1_m: 0.8794 - precision_m: 0.9230 - recall_m: 0.8410 - val_loss: 0.3584 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 41ms/epoch - 10ms/step\n",
            "Epoch 32/100\n",
            "4/4 - 0s - loss: 0.3413 - accuracy: 0.8829 - f1_m: 0.8815 - precision_m: 0.9099 - recall_m: 0.8554 - val_loss: 0.3591 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 9ms/step\n",
            "Epoch 33/100\n",
            "4/4 - 0s - loss: 0.3384 - accuracy: 0.8800 - f1_m: 0.8727 - precision_m: 0.9304 - recall_m: 0.8262 - val_loss: 0.3700 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 34/100\n",
            "4/4 - 0s - loss: 0.3352 - accuracy: 0.8800 - f1_m: 0.8812 - precision_m: 0.9126 - recall_m: 0.8552 - val_loss: 0.3769 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 40ms/epoch - 10ms/step\n",
            "Epoch 35/100\n",
            "4/4 - 0s - loss: 0.3332 - accuracy: 0.8800 - f1_m: 0.8921 - precision_m: 0.9337 - recall_m: 0.8555 - val_loss: 0.3811 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 33ms/epoch - 8ms/step\n",
            "Epoch 36/100\n",
            "4/4 - 0s - loss: 0.3302 - accuracy: 0.8800 - f1_m: 0.8833 - precision_m: 0.9284 - recall_m: 0.8451 - val_loss: 0.3796 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 37/100\n",
            "4/4 - 0s - loss: 0.3264 - accuracy: 0.8800 - f1_m: 0.8810 - precision_m: 0.9287 - recall_m: 0.8415 - val_loss: 0.3726 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 39ms/epoch - 10ms/step\n",
            "Epoch 38/100\n",
            "4/4 - 0s - loss: 0.3246 - accuracy: 0.8914 - f1_m: 0.8932 - precision_m: 0.9211 - recall_m: 0.8674 - val_loss: 0.3684 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 34ms/epoch - 8ms/step\n",
            "Epoch 39/100\n",
            "4/4 - 0s - loss: 0.3241 - accuracy: 0.8943 - f1_m: 0.8961 - precision_m: 0.9071 - recall_m: 0.8855 - val_loss: 0.3681 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 40ms/epoch - 10ms/step\n",
            "Epoch 40/100\n",
            "4/4 - 0s - loss: 0.3219 - accuracy: 0.8943 - f1_m: 0.9027 - precision_m: 0.9253 - recall_m: 0.8836 - val_loss: 0.3769 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 33ms/epoch - 8ms/step\n",
            "Epoch 41/100\n",
            "4/4 - 0s - loss: 0.3195 - accuracy: 0.8943 - f1_m: 0.8957 - precision_m: 0.9261 - recall_m: 0.8693 - val_loss: 0.3859 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 9ms/step\n",
            "Epoch 42/100\n",
            "4/4 - 0s - loss: 0.3169 - accuracy: 0.8886 - f1_m: 0.8830 - precision_m: 0.9368 - recall_m: 0.8416 - val_loss: 0.3870 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 46ms/epoch - 11ms/step\n",
            "Epoch 43/100\n",
            "4/4 - 0s - loss: 0.3147 - accuracy: 0.8943 - f1_m: 0.8916 - precision_m: 0.9186 - recall_m: 0.8667 - val_loss: 0.3809 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 44/100\n",
            "4/4 - 0s - loss: 0.3130 - accuracy: 0.8914 - f1_m: 0.8922 - precision_m: 0.9176 - recall_m: 0.8712 - val_loss: 0.3807 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 38ms/epoch - 10ms/step\n",
            "Epoch 45/100\n",
            "4/4 - 0s - loss: 0.3112 - accuracy: 0.8971 - f1_m: 0.9065 - precision_m: 0.9143 - recall_m: 0.8996 - val_loss: 0.3794 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 46/100\n",
            "4/4 - 0s - loss: 0.3096 - accuracy: 0.8971 - f1_m: 0.9018 - precision_m: 0.9157 - recall_m: 0.8894 - val_loss: 0.3867 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 43ms/epoch - 11ms/step\n",
            "Epoch 47/100\n",
            "4/4 - 0s - loss: 0.3081 - accuracy: 0.8943 - f1_m: 0.8952 - precision_m: 0.9181 - recall_m: 0.8760 - val_loss: 0.3918 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 56ms/epoch - 14ms/step\n",
            "Epoch 48/100\n",
            "4/4 - 0s - loss: 0.3067 - accuracy: 0.8943 - f1_m: 0.8982 - precision_m: 0.9167 - recall_m: 0.8818 - val_loss: 0.3855 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 33ms/epoch - 8ms/step\n",
            "Epoch 49/100\n",
            "4/4 - 0s - loss: 0.3039 - accuracy: 0.8971 - f1_m: 0.9086 - precision_m: 0.9234 - recall_m: 0.8949 - val_loss: 0.3888 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 33ms/epoch - 8ms/step\n",
            "Epoch 50/100\n",
            "4/4 - 0s - loss: 0.3016 - accuracy: 0.8943 - f1_m: 0.9017 - precision_m: 0.9170 - recall_m: 0.8872 - val_loss: 0.3939 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 42ms/epoch - 11ms/step\n",
            "Epoch 51/100\n",
            "4/4 - 0s - loss: 0.3006 - accuracy: 0.8943 - f1_m: 0.8900 - precision_m: 0.9228 - recall_m: 0.8605 - val_loss: 0.3977 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 42ms/epoch - 10ms/step\n",
            "Epoch 52/100\n",
            "4/4 - 0s - loss: 0.2993 - accuracy: 0.8943 - f1_m: 0.9095 - precision_m: 0.9311 - recall_m: 0.8917 - val_loss: 0.3922 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 53/100\n",
            "4/4 - 0s - loss: 0.2971 - accuracy: 0.8914 - f1_m: 0.8946 - precision_m: 0.9220 - recall_m: 0.8718 - val_loss: 0.3955 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 54/100\n",
            "4/4 - 0s - loss: 0.2957 - accuracy: 0.8943 - f1_m: 0.9036 - precision_m: 0.9214 - recall_m: 0.8865 - val_loss: 0.3915 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 55/100\n",
            "4/4 - 0s - loss: 0.2932 - accuracy: 0.8971 - f1_m: 0.8971 - precision_m: 0.9126 - recall_m: 0.8822 - val_loss: 0.3964 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 56/100\n",
            "4/4 - 0s - loss: 0.2918 - accuracy: 0.8943 - f1_m: 0.8966 - precision_m: 0.9168 - recall_m: 0.8801 - val_loss: 0.3956 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 34ms/epoch - 9ms/step\n",
            "Epoch 57/100\n",
            "4/4 - 0s - loss: 0.2896 - accuracy: 0.8971 - f1_m: 0.8983 - precision_m: 0.9156 - recall_m: 0.8841 - val_loss: 0.3986 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 41ms/epoch - 10ms/step\n",
            "Epoch 58/100\n",
            "4/4 - 0s - loss: 0.2878 - accuracy: 0.9000 - f1_m: 0.9040 - precision_m: 0.9197 - recall_m: 0.8893 - val_loss: 0.3965 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 42ms/epoch - 10ms/step\n",
            "Epoch 59/100\n",
            "4/4 - 0s - loss: 0.2859 - accuracy: 0.9000 - f1_m: 0.8952 - precision_m: 0.9051 - recall_m: 0.8893 - val_loss: 0.3976 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 32ms/epoch - 8ms/step\n",
            "Epoch 60/100\n",
            "4/4 - 0s - loss: 0.2838 - accuracy: 0.8971 - f1_m: 0.9109 - precision_m: 0.9314 - recall_m: 0.8914 - val_loss: 0.4032 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 61/100\n",
            "4/4 - 0s - loss: 0.2837 - accuracy: 0.9000 - f1_m: 0.8986 - precision_m: 0.9367 - recall_m: 0.8658 - val_loss: 0.4085 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "4/4 - 0s - loss: 0.2804 - accuracy: 0.9000 - f1_m: 0.9011 - precision_m: 0.9312 - recall_m: 0.8733 - val_loss: 0.3964 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 63/100\n",
            "4/4 - 0s - loss: 0.2792 - accuracy: 0.9029 - f1_m: 0.9037 - precision_m: 0.9248 - recall_m: 0.8870 - val_loss: 0.3899 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 37ms/epoch - 9ms/step\n",
            "Epoch 64/100\n",
            "4/4 - 0s - loss: 0.2777 - accuracy: 0.9057 - f1_m: 0.9061 - precision_m: 0.9306 - recall_m: 0.8859 - val_loss: 0.3941 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 40ms/epoch - 10ms/step\n",
            "Epoch 65/100\n",
            "4/4 - 0s - loss: 0.2756 - accuracy: 0.9057 - f1_m: 0.8965 - precision_m: 0.9202 - recall_m: 0.8786 - val_loss: 0.3973 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 44ms/epoch - 11ms/step\n",
            "Epoch 66/100\n",
            "4/4 - 0s - loss: 0.2742 - accuracy: 0.9029 - f1_m: 0.9064 - precision_m: 0.9151 - recall_m: 0.8993 - val_loss: 0.3954 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 67/100\n",
            "4/4 - 0s - loss: 0.2716 - accuracy: 0.9029 - f1_m: 0.9148 - precision_m: 0.9239 - recall_m: 0.9070 - val_loss: 0.4007 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 68/100\n",
            "4/4 - 0s - loss: 0.2701 - accuracy: 0.9086 - f1_m: 0.9030 - precision_m: 0.9252 - recall_m: 0.8820 - val_loss: 0.4106 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 34ms/epoch - 8ms/step\n",
            "Epoch 69/100\n",
            "4/4 - 0s - loss: 0.2687 - accuracy: 0.9057 - f1_m: 0.9068 - precision_m: 0.9307 - recall_m: 0.8866 - val_loss: 0.4048 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 70/100\n",
            "4/4 - 0s - loss: 0.2666 - accuracy: 0.9086 - f1_m: 0.9117 - precision_m: 0.9283 - recall_m: 0.8965 - val_loss: 0.4049 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 38ms/epoch - 9ms/step\n",
            "Epoch 71/100\n",
            "4/4 - 0s - loss: 0.2647 - accuracy: 0.9086 - f1_m: 0.9127 - precision_m: 0.9203 - recall_m: 0.9071 - val_loss: 0.4052 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 72/100\n",
            "4/4 - 0s - loss: 0.2633 - accuracy: 0.9114 - f1_m: 0.9211 - precision_m: 0.9369 - recall_m: 0.9069 - val_loss: 0.4181 - val_accuracy: 0.8621 - val_f1_m: 0.8537 - val_precision_m: 1.0000 - val_recall_m: 0.7447 - 37ms/epoch - 9ms/step\n",
            "Epoch 73/100\n",
            "4/4 - 0s - loss: 0.2618 - accuracy: 0.9086 - f1_m: 0.9081 - precision_m: 0.9325 - recall_m: 0.8861 - val_loss: 0.4160 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 39ms/epoch - 10ms/step\n",
            "Epoch 74/100\n",
            "4/4 - 0s - loss: 0.2608 - accuracy: 0.9057 - f1_m: 0.9171 - precision_m: 0.9318 - recall_m: 0.9048 - val_loss: 0.4012 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 39ms/epoch - 10ms/step\n",
            "Epoch 75/100\n",
            "4/4 - 0s - loss: 0.2575 - accuracy: 0.9171 - f1_m: 0.9221 - precision_m: 0.9162 - recall_m: 0.9319 - val_loss: 0.4039 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 40ms/epoch - 10ms/step\n",
            "Epoch 76/100\n",
            "4/4 - 0s - loss: 0.2560 - accuracy: 0.9143 - f1_m: 0.9223 - precision_m: 0.9351 - recall_m: 0.9106 - val_loss: 0.4213 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 40ms/epoch - 10ms/step\n",
            "Epoch 77/100\n",
            "4/4 - 0s - loss: 0.2547 - accuracy: 0.9086 - f1_m: 0.9113 - precision_m: 0.9281 - recall_m: 0.8962 - val_loss: 0.4163 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 78/100\n",
            "4/4 - 0s - loss: 0.2530 - accuracy: 0.9200 - f1_m: 0.9264 - precision_m: 0.9383 - recall_m: 0.9170 - val_loss: 0.4062 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 41ms/epoch - 10ms/step\n",
            "Epoch 79/100\n",
            "4/4 - 0s - loss: 0.2506 - accuracy: 0.9200 - f1_m: 0.9257 - precision_m: 0.9279 - recall_m: 0.9244 - val_loss: 0.4065 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 45ms/epoch - 11ms/step\n",
            "Epoch 80/100\n",
            "4/4 - 0s - loss: 0.2481 - accuracy: 0.9257 - f1_m: 0.9319 - precision_m: 0.9299 - recall_m: 0.9344 - val_loss: 0.4152 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 81/100\n",
            "4/4 - 0s - loss: 0.2472 - accuracy: 0.9229 - f1_m: 0.9323 - precision_m: 0.9460 - recall_m: 0.9215 - val_loss: 0.4194 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 36ms/epoch - 9ms/step\n",
            "Epoch 82/100\n",
            "4/4 - 0s - loss: 0.2457 - accuracy: 0.9229 - f1_m: 0.9288 - precision_m: 0.9381 - recall_m: 0.9198 - val_loss: 0.4108 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 37ms/epoch - 9ms/step\n",
            "Epoch 83/100\n",
            "4/4 - 0s - loss: 0.2434 - accuracy: 0.9229 - f1_m: 0.9345 - precision_m: 0.9325 - recall_m: 0.9390 - val_loss: 0.4080 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 34ms/epoch - 8ms/step\n",
            "Epoch 84/100\n",
            "4/4 - 0s - loss: 0.2417 - accuracy: 0.9229 - f1_m: 0.9246 - precision_m: 0.9232 - recall_m: 0.9262 - val_loss: 0.4114 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 37ms/epoch - 9ms/step\n",
            "Epoch 85/100\n",
            "4/4 - 0s - loss: 0.2399 - accuracy: 0.9257 - f1_m: 0.9232 - precision_m: 0.9216 - recall_m: 0.9253 - val_loss: 0.4156 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 35ms/epoch - 9ms/step\n",
            "Epoch 86/100\n",
            "4/4 - 0s - loss: 0.2380 - accuracy: 0.9229 - f1_m: 0.9280 - precision_m: 0.9336 - recall_m: 0.9229 - val_loss: 0.4179 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 38ms/epoch - 10ms/step\n",
            "Epoch 87/100\n",
            "4/4 - 0s - loss: 0.2360 - accuracy: 0.9257 - f1_m: 0.9324 - precision_m: 0.9406 - recall_m: 0.9251 - val_loss: 0.4170 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 35ms/epoch - 9ms/step\n",
            "Epoch 88/100\n",
            "4/4 - 0s - loss: 0.2343 - accuracy: 0.9257 - f1_m: 0.9309 - precision_m: 0.9417 - recall_m: 0.9215 - val_loss: 0.4140 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 43ms/epoch - 11ms/step\n",
            "Epoch 89/100\n",
            "4/4 - 0s - loss: 0.2330 - accuracy: 0.9257 - f1_m: 0.9366 - precision_m: 0.9450 - recall_m: 0.9316 - val_loss: 0.4167 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 39ms/epoch - 10ms/step\n",
            "Epoch 90/100\n",
            "4/4 - 0s - loss: 0.2318 - accuracy: 0.9229 - f1_m: 0.9223 - precision_m: 0.9254 - recall_m: 0.9209 - val_loss: 0.4158 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 33ms/epoch - 8ms/step\n",
            "Epoch 91/100\n",
            "4/4 - 0s - loss: 0.2295 - accuracy: 0.9200 - f1_m: 0.9272 - precision_m: 0.9247 - recall_m: 0.9302 - val_loss: 0.4195 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 38ms/epoch - 10ms/step\n",
            "Epoch 92/100\n",
            "4/4 - 0s - loss: 0.2309 - accuracy: 0.9257 - f1_m: 0.9284 - precision_m: 0.9324 - recall_m: 0.9259 - val_loss: 0.4403 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 42ms/epoch - 10ms/step\n",
            "Epoch 93/100\n",
            "4/4 - 0s - loss: 0.2252 - accuracy: 0.9286 - f1_m: 0.9264 - precision_m: 0.9455 - recall_m: 0.9091 - val_loss: 0.4298 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 36ms/epoch - 9ms/step\n",
            "Epoch 94/100\n",
            "4/4 - 0s - loss: 0.2243 - accuracy: 0.9257 - f1_m: 0.9262 - precision_m: 0.9219 - recall_m: 0.9305 - val_loss: 0.4211 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 43ms/epoch - 11ms/step\n",
            "Epoch 95/100\n",
            "4/4 - 0s - loss: 0.2213 - accuracy: 0.9314 - f1_m: 0.9354 - precision_m: 0.9392 - recall_m: 0.9337 - val_loss: 0.4354 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 41ms/epoch - 10ms/step\n",
            "Epoch 96/100\n",
            "4/4 - 0s - loss: 0.2188 - accuracy: 0.9257 - f1_m: 0.9279 - precision_m: 0.9359 - recall_m: 0.9202 - val_loss: 0.4416 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 37ms/epoch - 9ms/step\n",
            "Epoch 97/100\n",
            "4/4 - 0s - loss: 0.2176 - accuracy: 0.9257 - f1_m: 0.9314 - precision_m: 0.9464 - recall_m: 0.9195 - val_loss: 0.4414 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 41ms/epoch - 10ms/step\n",
            "Epoch 98/100\n",
            "4/4 - 0s - loss: 0.2149 - accuracy: 0.9257 - f1_m: 0.9320 - precision_m: 0.9386 - recall_m: 0.9258 - val_loss: 0.4297 - val_accuracy: 0.8621 - val_f1_m: 0.8571 - val_precision_m: 0.9730 - val_recall_m: 0.7660 - 38ms/epoch - 9ms/step\n",
            "Epoch 99/100\n",
            "4/4 - 0s - loss: 0.2160 - accuracy: 0.9257 - f1_m: 0.9345 - precision_m: 0.9212 - recall_m: 0.9514 - val_loss: 0.4323 - val_accuracy: 0.8506 - val_f1_m: 0.8471 - val_precision_m: 0.9474 - val_recall_m: 0.7660 - 37ms/epoch - 9ms/step\n",
            "Epoch 100/100\n",
            "4/4 - 0s - loss: 0.2103 - accuracy: 0.9314 - f1_m: 0.9416 - precision_m: 0.9401 - recall_m: 0.9433 - val_loss: 0.4591 - val_accuracy: 0.8506 - val_f1_m: 0.8434 - val_precision_m: 0.9722 - val_recall_m: 0.7447 - 39ms/epoch - 10ms/step\n",
            "Accuracy: 85.06\n",
            "f1_score\n",
            "0.8232803344726562\n",
            "Accuracy: 83.29\n",
            "f1_score: 0.8317\n"
          ]
        }
      ]
    }
  ]
}